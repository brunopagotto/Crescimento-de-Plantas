---
title: "Foliar"
author: "Ana Carolina Murad Lima"
date: "2023-06-22"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Bibliotecas
library(readxl)
library(dplyr)
library(ggplot2)
```

### CICLO 1 ###

```{r}
# Leitura e tratamento dos dados
dados <- read_excel("Foliar ok.xlsx")

# Ordenar o dataframe por quatro colunas diferentes
dados <- with(dados, dados[order(CICLO, BLOCO, EFLUENTE, INOCULO), ])

# Converter as colunas para tipo numérico e arredondar valores em duas casas
for (i in 5:7) {
  dados[, i] <- as.numeric(unlist(dados[, i]))
}
dados[5:7] =  round(dados[5:7], digits = 2)
str(dados)
```

```{r}
# Transformar as colunas em variáveis categóricas
dados$BLOCO <- factor(dados$BLOCO)
dados$CICLO <- factor(dados$CICLO)
dados$INOCULO <- factor(dados$INOCULO)
dados$EFLUENTE <- factor(dados$EFLUENTE)
```

```{r}
# Níveis para cada fator de tratamentos
library(dae)
n.F <- 2
n.D <- 5
n.Bloco <- 4
tr <- data.frame(cbind(INOCULO = paste("I", rep(1:n.F, each = n.D, times =
                                                  n.Bloco),
                                       sep = ""),
                       EFLUENTE = paste("E", rep(1:n.D, times = n.F*n.Bloco),
                                        sep = "")))
units <- list(Bloco = n.Bloco,
              Parcela = (n.F*n.D))
nest <- list(Parcela = "Bloco")
(lay <- designRandomize(allocated = tr,
                        recipient = units,
                        nested.recipients = nest,
                        seed = 9719532))

table(lay$I)
table(lay$E)

lay$Tratamento <- factor(paste(lay$I, lay$E, sep = ":"))
print(lay$Tratamento)
```

```{r}
# Usar apenas dados do Ciclo 1
dados = subset(dados, CICLO == 1)
```

```{r}
# Separar os dados de acordo com o período de tempo da coleta
dados_1 = dados[c(1:5)]
dados_2 = dados[c(1:4,6)]
dados_3 = dados[c(1:4,7)]
dados_4 = dados[c(1:4,8)]
dados_5 = dados[c(1:4,9)]
dados_6 = dados[c(1:4,10)]
dados_7 = dados[c(1:4,11)]

# Estrutura dos dados após separados
"dados_1"
str(dados_1)
"dados_2"
str(dados_2)
"dados_3"
str(dados_3)
"dados_4"
str(dados_4)
"dados_5"
str(dados_5)
"dados_6"
str(dados_5)
"dados_7"
str(dados_5)
```

### Análise para Nitrogênio ###

```{r}
# Gráficos com os boxplots para cada combinação de todos os fatores
ggplot(dados_1, aes(x = factor(EFLUENTE), y = N)) +
  geom_boxplot() +
  facet_grid(INOCULO ~ CICLO) +
  labs(x = "EFLUENTE", y = "Nitrogênio") +
  ggtitle("Boxplots por combinação dos fatores")
```

```{r}
# Calcular os limites inferiores de outliers para cada combinação de fatores
limites_outliers <- aggregate(N ~ EFLUENTE + INOCULO + CICLO, 
                              data = dados_1, FUN = function(x) {
  q <- quantile(x, c(0.25, 0.75), na.rm = TRUE)
  iqr <- q[2] - q[1]
  limite_inferior <- q[1] - 1.5 * iqr
})

# Armazenar vetor com os limites inferiores
lim_inf = limites_outliers$N

# Calcular os limites superiores de outliers para cada combinação de fatores
limites_outliers <- aggregate(N ~ EFLUENTE + INOCULO + CICLO, 
                              data = dados_1, FUN = function(x) {
  q <- quantile(x, c(0.25, 0.75), na.rm = TRUE)
  iqr <- q[2] - q[1]
  limite_superior <- q[2] + 1.5 * iqr
})

# Armazenar vetor com os limites superiores
lim_sup = limites_outliers$N

# Montar Dataframe com os limites inferior e superior
limites_outliers = limites_outliers[c(1:3)]
limites_outliers$LIM_INF = lim_inf
limites_outliers$LIM_SUP = lim_sup

# Definir o número de replicação de acordo com o valor de CICLO
num_rep <- ifelse(limites_outliers$CICLO == 1, 4, 3)

# Replicar as linhas do dataframe
limites_outliers <- limites_outliers[rep(row.names(limites_outliers), 
                                         num_rep), ]

# Redefinir os índices das linhas
rownames(limites_outliers) <- NULL

# Reordenar os dados do tempo 1 seguindo a combinação de fatores por cada bloco
blocos_dados_1 <- with(dados_1, 
                             dados_1[order(CICLO, INOCULO, EFLUENTE), ])

# Definir como NA (valor ausente) os outliers
blocos_dados_1$N[which(blocos_dados_1$N < 
                                    limites_outliers$LIM_INF)] = NA
blocos_dados_1$N[which(blocos_dados_1$N > 
                                    limites_outliers$LIM_SUP)] = NA

# Calcular a média para cada grupo de 4 linhas
media_blocos_1 = aggregate(N ~ EFLUENTE + INOCULO + CICLO, 
                                 data = blocos_dados_1, FUN = mean)

# Replicar cada linha por 4 vezes
media_blocos_1 = media_blocos_1[rep(row.names(media_blocos_1), 
                                                each = 4), ]

# Redefinir os índices das linhas
rownames(media_blocos_1) <- NULL

# Preencher os NA's com as médias dos 4 blocos para a 
# combinação de fatores específica
blocos_dados_1$N[which(is.na(blocos_dados_1$N))] =
  media_blocos_1$N[which(is.na(blocos_dados_1$N))]
```


```{r}
# Análises Descritivas
str(blocos_dados_1)
summary(blocos_dados_1)

# Número de observações
with(blocos_dados_1, tapply(N, list(EFLUENTE, INOCULO), length))
with(blocos_dados_1, tapply(N, list(EFLUENTE, INOCULO), sum))
with(blocos_dados_1, tapply(N, list(EFLUENTE, INOCULO), mean))
with(blocos_dados_1, tapply(N, list(EFLUENTE, INOCULO), var))
with(blocos_dados_1, tapply(N, list(EFLUENTE, INOCULO), sd))

# Tamanho das Médias
T.medias <- with(blocos_dados_1,
                 model.tables(aov(N ~ BLOCO + EFLUENTE + INOCULO +
                                    EFLUENTE:INOCULO),
                              "means"))
T.medias
```

```{r}
# Media dos blocos para fazer os testes de Normalidade e Homocedasticidade
media_blocos_1 = aggregate(N ~ EFLUENTE + INOCULO + CICLO, 
                                 data = blocos_dados_1, FUN = mean)

# Realizar o teste Shapiro-Wilk no conjunto de dados completo
resultado_shapiro <- shapiro.test(media_blocos_1$N)$p.value

# Exibir o resultado do teste Shapiro-Wilk
print(resultado_shapiro)

# Interpretação do p-valor
if (resultado_shapiro > 0.05) {
  print("Os dados seguem uma distribuição normal.")
} else {
  print("Os dados não seguem uma distribuição normal.")
}
```

```{r}
# Realizar o teste de Bartlett no conjunto de dados completo
resultado_bartlett <- bartlett.test(media_blocos_1$N, 
                                    media_blocos_1$EFLUENTE, 
                                    media_blocos_1$INOCULO,
                                    media_blocos_1$CICLO)$p.value

# Exibir o resultado do teste de Bartlett
print(resultado_bartlett)

# Interpretação do p-valor
if (resultado_bartlett > 0.05) {
  print("A variância é homogênea entre os grupos.")
} else {
  print("A variância não é homogênea entre os grupos.")
}
```

```{r}
# Ajustar o modelo linear para parcelas subdivididas
modelo_PARCELASUB = aov(N ~ BLOCO + INOCULO * EFLUENTE + 
                          Error(BLOCO*INOCULO), data = blocos_dados_1)

# Visualizar os resultados do modelo
summary(modelo_PARCELASUB)
modelo = modelo_PARCELASUB
```

```{r}
# Refazer o modelo sem o erro, apenas para facilitar as funções subsequentes
modelo = aov(N ~ BLOCO + INOCULO * EFLUENTE,
             data = blocos_dados_1)

# Realizar a análise de variância (ANOVA)
anova_result <- anova(modelo)

# Filtrar apenas os fatores significativos ao nível 0.05
fatores_significativos <- anova_result[anova_result$"Pr(>F)" < 0.05, ]

# Exibir as interações significativas
print(fatores_significativos)
```

```{r}
# Vetor com os fatores significativos
nomes_linhas = row.names(fatores_significativos)

# Filtrar apenas as interações
interacoes_significativas <- nomes_linhas[nchar(nomes_linhas) > 8]

# Exibir o resultado
print(interacoes_significativas)
```

```{r}
# Realizar o teste de Tukey para todas as interações significativas
tukey_result <- TukeyHSD(modelo)
```

```{r}
for (i in 1:length(interacoes_significativas)) {
  if (length(interacoes_significativas) == 0){
    break
  }
  interacao = interacoes_significativas[i]
  partes <- strsplit(interacao, split = ":")
  if (nchar(interacao) < 20){
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- 0
  }
  else{
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- partes[[1]][3]
  }
  
  if(fator1 == "INOCULO" && fator2 == "EFLUENTE" && fator3 == 0){
    media_interacao <- aggregate(N ~ INOCULO + EFLUENTE, 
                             data = blocos_dados_1, FUN = mean)
    print(media_interacao)
  }

}
```

```{r}
for (i in 1:length(interacoes_significativas)) {
  if (length(interacoes_significativas) == 0){
    break
  }
  interacao = interacoes_significativas[i]
  partes <- strsplit(interacao, split = ":")
  if (nchar(interacao) < 20){
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- 0
  }
  else{
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- partes[[1]][3]
  }
  
  inter_tukey = tukey_result[interacao]
  inter_tukey = data.frame(inter_tukey)
  colnames(inter_tukey) = c('diif','lwr','upr','p_adj')
  inter_tukey = subset(inter_tukey, p_adj < 0.05)
  print(inter_tukey)
}
```

### Análise para Fósforo ###

```{r}
# Gráficos com os boxplots para cada combinação de todos os fatores
ggplot(dados_2, aes(x = factor(EFLUENTE), y = P)) +
  geom_boxplot() +
  facet_grid(INOCULO ~ CICLO) +
  labs(x = "EFLUENTE", y = "Fósforo") +
  ggtitle("Boxplots por combinação dos fatores")
```

```{r}
# Calcular os limites inferiores de outliers para cada combinação de fatores
limites_outliers <- aggregate(P ~ EFLUENTE + INOCULO + CICLO, 
                              data = dados_2, FUN = function(x) {
  q <- quantile(x, c(0.25, 0.75), na.rm = TRUE)
  iqr <- q[2] - q[1]
  limite_inferior <- q[1] - 1.5 * iqr
})

# Armazenar vetor com os limites inferiores
lim_inf = limites_outliers$P

# Calcular os limites superiores de outliers para cada combinação de fatores
limites_outliers <- aggregate(P ~ EFLUENTE + INOCULO + CICLO, 
                              data = dados_2, FUN = function(x) {
  q <- quantile(x, c(0.25, 0.75), na.rm = TRUE)
  iqr <- q[2] - q[1]
  limite_superior <- q[2] + 1.5 * iqr
})

# Armazenar vetor com os limites superiores
lim_sup = limites_outliers$P

# Montar Dataframe com os limites inferior e superior
limites_outliers = limites_outliers[c(1:3)]
limites_outliers$LIM_INF = lim_inf
limites_outliers$LIM_SUP = lim_sup

# Definir o número de replicação de acordo com o valor de CICLO
num_rep <- ifelse(limites_outliers$CICLO == 1, 4, 3)

# Replicar as linhas do dataframe
limites_outliers <- limites_outliers[rep(row.names(limites_outliers), 
                                         num_rep), ]

# Redefinir os índices das linhas
rownames(limites_outliers) <- NULL

# Reordenar os dados do tempo 1 seguindo a combinação de fatores por cada bloco
blocos_dados_2 <- with(dados_2, 
                             dados_2[order(CICLO, INOCULO, EFLUENTE), ])

# Definir como NA (valor ausente) os outliers
blocos_dados_2$P[which(blocos_dados_2$P < 
                                    limites_outliers$LIM_INF)] = NA
blocos_dados_2$P[which(blocos_dados_2$P > 
                                    limites_outliers$LIM_SUP)] = NA

# Calcular a média para cada grupo de 4 linhas
media_blocos_2 = aggregate(P ~ EFLUENTE + INOCULO + CICLO, 
                                 data = blocos_dados_2, FUN = mean)

# Replicar cada linha por 4 vezes
media_blocos_2 = media_blocos_2[rep(row.names(media_blocos_2), 
                                                each = 4), ]

# Redefinir os índices das linhas
rownames(media_blocos_2) <- NULL

# Preencher os NA's com as médias dos 4 blocos para a 
# combinação de fatores específica
blocos_dados_2$P[which(is.na(blocos_dados_2$P))] =
  media_blocos_2$P[which(is.na(blocos_dados_2$P))]

```

```{r}
# Análises Descritivas
str(blocos_dados_2)
summary(blocos_dados_2)

# Número de observações
with(blocos_dados_2, tapply(P, list(EFLUENTE, INOCULO), length))
with(blocos_dados_2, tapply(P, list(EFLUENTE, INOCULO), sum))
with(blocos_dados_2, tapply(P, list(EFLUENTE, INOCULO), mean))
with(blocos_dados_2, tapply(P, list(EFLUENTE, INOCULO), var))
with(blocos_dados_2, tapply(P, list(EFLUENTE, INOCULO), sd))

# Tamanho das Médias
T.medias <- with(blocos_dados_2,
                 model.tables(aov(P ~ BLOCO + EFLUENTE + INOCULO +
                                    EFLUENTE:INOCULO),
                              "means"))
T.medias
```

```{r}
# Media dos blocos para fazer os testes de Normalidade e Homocedasticidade
media_blocos_2 = aggregate(P ~ EFLUENTE + INOCULO + CICLO, 
                                 data = blocos_dados_2, FUN = mean)

# Realizar o teste Shapiro-Wilk no conjunto de dados completo
resultado_shapiro <- shapiro.test(media_blocos_2$P)$p.value

# Exibir o resultado do teste Shapiro-Wilk
print(resultado_shapiro)

# Interpretação do p-valor
if (resultado_shapiro > 0.05) {
  print("Os dados seguem uma distribuição normal.")
} else {
  print("Os dados não seguem uma distribuição normal.")
}
```

```{r}
# Realizar o teste de Bartlett no conjunto de dados completo
resultado_bartlett <- bartlett.test(media_blocos_2$P, 
                                    media_blocos_2$EFLUENTE, 
                                    media_blocos_2$INOCULO,
                                    media_blocos_2$CICLO)$p.value

# Exibir o resultado do teste de Bartlett
print(resultado_bartlett)

# Interpretação do p-valor
if (resultado_bartlett > 0.05) {
  print("A variância é homogênea entre os grupos.")
} else {
  print("A variância não é homogênea entre os grupos.")
}
```

```{r}
# Ajustar o modelo linear para parcelas subdivididas
modelo_PARCELASUB = aov(P ~ BLOCO + INOCULO * EFLUENTE + 
                          Error(BLOCO*INOCULO), data = blocos_dados_2)

# Visualizar os resultados do modelo
summary(modelo_PARCELASUB)
modelo = modelo_PARCELASUB
```

```{r}
# Refazer o modelo sem o erro, apenas para facilitar as funções subsequentes
modelo = aov(P ~ BLOCO + INOCULO * EFLUENTE,
             data = blocos_dados_2)

# Realizar a análise de variância (ANOVA)
anova_result <- anova(modelo)

# Filtrar apenas os fatores significativos ao nível 0.05
fatores_significativos <- anova_result[anova_result$"Pr(>F)" < 0.05, ]

# Exibir as interações significativas
print(fatores_significativos)
```

```{r}
# Vetor com os fatores significativos
nomes_linhas = row.names(fatores_significativos)

# Filtrar apenas as interações
interacoes_significativas <- nomes_linhas[nchar(nomes_linhas) > 8]

# Exibir o resultado
print(interacoes_significativas)
```

```{r}
# Realizar o teste de Tukey para todas as interações significativas
tukey_result <- TukeyHSD(modelo)
```

```{r}
for (i in 1:length(interacoes_significativas)) {
  if (length(interacoes_significativas) == 0){
    break
  }
  interacao = interacoes_significativas[i]
  partes <- strsplit(interacao, split = ":")
  if (nchar(interacao) < 20){
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- 0
  }
  else{
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- partes[[1]][3]
  }
  
  if(fator1 == "INOCULO" && fator2 == "EFLUENTE" && fator3 == 0){
    media_interacao <- aggregate(P ~ INOCULO + EFLUENTE, 
                             data = blocos_dados_2, FUN = mean)
    print(media_interacao)
  }

}
```

```{r}
for (i in 1:length(interacoes_significativas)) {
  if (length(interacoes_significativas) == 0){
    break
  }
  interacao = interacoes_significativas[i]
  partes <- strsplit(interacao, split = ":")
  if (nchar(interacao) < 20){
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- 0
  }
  else{
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- partes[[1]][3]
  }
  
  inter_tukey = tukey_result[interacao]
  inter_tukey = data.frame(inter_tukey)
  colnames(inter_tukey) = c('diif','lwr','upr','p_adj')
  inter_tukey = subset(inter_tukey, p_adj < 0.05)
  print(inter_tukey)
}
```

### Análise para Potássio ###

```{r}
# Gráficos com os boxplots para cada combinação de todos os fatores
ggplot(dados_3, aes(x = factor(EFLUENTE), y = K)) +
  geom_boxplot() +
  facet_grid(INOCULO ~ CICLO) +
  labs(x = "EFLUENTE", y = "Potássio") +
  ggtitle("Boxplots por combinação dos fatores")
```

```{r}
# Calcular os limites inferiores de outliers para cada combinação de fatores
limites_outliers <- aggregate(K ~ EFLUENTE + INOCULO + CICLO, 
                              data = dados_3, FUN = function(x) {
  q <- quantile(x, c(0.25, 0.75), na.rm = TRUE)
  iqr <- q[2] - q[1]
  limite_inferior <- q[1] - 1.5 * iqr
})

# Armazenar vetor com os limites inferiores
lim_inf = limites_outliers$K

# Calcular os limites superiores de outliers para cada combinação de fatores
limites_outliers <- aggregate(K ~ EFLUENTE + INOCULO + CICLO, 
                              data = dados_3, FUN = function(x) {
  q <- quantile(x, c(0.25, 0.75), na.rm = TRUE)
  iqr <- q[2] - q[1]
  limite_superior <- q[2] + 1.5 * iqr
})

# Armazenar vetor com os limites superiores
lim_sup = limites_outliers$K

# Montar Dataframe com os limites inferior e superior
limites_outliers = limites_outliers[c(1:3)]
limites_outliers$LIM_INF = lim_inf
limites_outliers$LIM_SUP = lim_sup

# Definir o número de replicação de acordo com o valor de CICLO
num_rep <- ifelse(limites_outliers$CICLO == 1, 4, 3)

# Replicar as linhas do dataframe
limites_outliers <- limites_outliers[rep(row.names(limites_outliers), 
                                         num_rep), ]

# Redefinir os índices das linhas
rownames(limites_outliers) <- NULL

# Reordenar os dados do tempo 1 seguindo a combinação de fatores por cada bloco
blocos_dados_3 <- with(dados_3, 
                             dados_3[order(CICLO, INOCULO, EFLUENTE), ])

# Definir como NA (valor ausente) os outliers
blocos_dados_3$K[which(blocos_dados_3$K < 
                                    limites_outliers$LIM_INF)] = NA
blocos_dados_3$K[which(blocos_dados_3$K > 
                                    limites_outliers$LIM_SUP)] = NA

# Calcular a média para cada grupo de 4 linhas
media_blocos_3 = aggregate(K ~ EFLUENTE + INOCULO + CICLO, 
                                 data = blocos_dados_3, FUN = mean)

# Replicar cada linha por 4 vezes
media_blocos_3 = media_blocos_3[rep(row.names(media_blocos_3), 
                                                each = 4), ]

# Redefinir os índices das linhas
rownames(media_blocos_3) <- NULL

# Preencher os NA's com as médias dos 4 blocos para a 
# combinação de fatores específica
blocos_dados_3$K[which(is.na(blocos_dados_3$K))] =
  media_blocos_3$K[which(is.na(blocos_dados_3$K))]

```

```{r}
# Análises Descritivas
str(blocos_dados_3)
summary(blocos_dados_3)

# Número de observações
with(blocos_dados_3, tapply(K, list(EFLUENTE, INOCULO), length))
with(blocos_dados_3, tapply(K, list(EFLUENTE, INOCULO), sum))
with(blocos_dados_3, tapply(K, list(EFLUENTE, INOCULO), mean))
with(blocos_dados_3, tapply(K, list(EFLUENTE, INOCULO), var))
with(blocos_dados_3, tapply(K, list(EFLUENTE, INOCULO), sd))

# Tamanho das Médias
T.medias <- with(blocos_dados_3,
                 model.tables(aov(K ~ BLOCO + EFLUENTE + INOCULO +
                                    EFLUENTE:INOCULO),
                              "means"))
T.medias
```

```{r}
# Media dos blocos para fazer os testes de Normalidade e Homocedasticidade
media_blocos_3 = aggregate(K ~ EFLUENTE + INOCULO + CICLO, 
                                 data = blocos_dados_3, FUN = mean)

# Realizar o teste Shapiro-Wilk no conjunto de dados completo
resultado_shapiro <- shapiro.test(media_blocos_3$K)$p.value

# Exibir o resultado do teste Shapiro-Wilk
print(resultado_shapiro)

# Interpretação do p-valor
if (resultado_shapiro > 0.05) {
  print("Os dados seguem uma distribuição normal.")
} else {
  print("Os dados não seguem uma distribuição normal.")
}
```
```{r}
# Realizar o teste de Bartlett no conjunto de dados completo
resultado_bartlett <- bartlett.test(media_blocos_3$K, 
                                    media_blocos_3$EFLUENTE, 
                                    media_blocos_3$INOCULO,
                                    media_blocos_3$CICLO)$p.value

# Exibir o resultado do teste de Bartlett
print(resultado_bartlett)

# Interpretação do p-valor
if (resultado_bartlett > 0.05) {
  print("A variância é homogênea entre os grupos.")
} else {
  print("A variância não é homogênea entre os grupos.")
}
```


```{r}
# Ajustar o modelo linear para parcelas subdivididas
modelo_PARCELASUB = aov(K ~ BLOCO + INOCULO * EFLUENTE + 
                          Error(BLOCO*INOCULO), data = blocos_dados_3)

# Visualizar os resultados do modelo
summary(modelo_PARCELASUB)
modelo = modelo_PARCELASUB
```

```{r}
# Refazer o modelo sem o erro, apenas para facilitar as funções subsequentes
modelo = aov(K ~ BLOCO + INOCULO * EFLUENTE,
             data = blocos_dados_3)

# Realizar a análise de variância (ANOVA)
anova_result <- anova(modelo)

# Filtrar apenas os fatores significativos ao nível 0.05
fatores_significativos <- anova_result[anova_result$"Pr(>F)" < 0.05, ]

# Exibir as interações significativas
print(fatores_significativos)
```

```{r}
# Vetor com os fatores significativos
nomes_linhas = row.names(fatores_significativos)

# Filtrar apenas as interações
interacoes_significativas <- nomes_linhas[nchar(nomes_linhas) > 8]

# Exibir o resultado
print(interacoes_significativas)
```

```{r}
# Realizar o teste de Tukey para todas as interações significativas
tukey_result <- TukeyHSD(modelo)
```

```{r}
for (i in 1:length(interacoes_significativas)) {
  if (length(interacoes_significativas) == 0){
    break
  }
  interacao = interacoes_significativas[i]
  partes <- strsplit(interacao, split = ":")
  if (nchar(interacao) < 20){
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- 0
  }
  else{
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- partes[[1]][3]
  }
  
  if(fator1 == "INOCULO" && fator2 == "EFLUENTE" && fator3 == 0){
    media_interacao <- aggregate(K ~ INOCULO + EFLUENTE, 
                             data = blocos_dados_3, FUN = mean)
    print(media_interacao)
  }

}
```

```{r}
for (i in 1:length(interacoes_significativas)) {
  if (length(interacoes_significativas) == 0){
    break
  }
  interacao = interacoes_significativas[i]
  partes <- strsplit(interacao, split = ":")
  if (nchar(interacao) < 20){
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- 0
  }
  else{
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- partes[[1]][3]
  }
  
  inter_tukey = tukey_result[interacao]
  inter_tukey = data.frame(inter_tukey)
  colnames(inter_tukey) = c('diif','lwr','upr','p_adj')
  inter_tukey = subset(inter_tukey, p_adj < 0.05)
  print(inter_tukey)
}
```

### Análise para Sódio ###

```{r}
# Gráficos com os boxplots para cada combinação de todos os fatores
ggplot(dados_4, aes(x = factor(EFLUENTE), y = Na)) +
  geom_boxplot() +
  facet_grid(INOCULO ~ CICLO) +
  labs(x = "EFLUENTE", y = "Na") +
  ggtitle("Boxplots por combinação dos fatores")
```

```{r}
# Calcular os limites inferiores de outliers para cada combinação de fatores
limites_outliers <- aggregate(Na ~ EFLUENTE + INOCULO + CICLO, 
                              data = dados_4, FUN = function(x) {
  q <- quantile(x, c(0.25, 0.75), na.rm = TRUE)
  iqr <- q[2] - q[1]
  limite_inferior <- q[1] - 1.5 * iqr
})

# Armazenar vetor com os limites inferiores
lim_inf = limites_outliers$Na

# Calcular os limites superiores de outliers para cada combinação de fatores
limites_outliers <- aggregate(Na ~ EFLUENTE + INOCULO + CICLO, 
                              data = dados_4, FUN = function(x) {
  q <- quantile(x, c(0.25, 0.75), na.rm = TRUE)
  iqr <- q[2] - q[1]
  limite_superior <- q[2] + 1.5 * iqr
})

# Armazenar vetor com os limites superiores
lim_sup = limites_outliers$Na

# Montar Dataframe com os limites inferior e superior
limites_outliers = limites_outliers[c(1:3)]
limites_outliers$LIM_INF = lim_inf
limites_outliers$LIM_SUP = lim_sup

# Definir o número de replicação de acordo com o valor de CICLO
num_rep <- ifelse(limites_outliers$CICLO == 1, 4, 3)

# Replicar as linhas do dataframe
limites_outliers <- limites_outliers[rep(row.names(limites_outliers), 
                                         num_rep), ]

# Redefinir os índices das linhas
rownames(limites_outliers) <- NULL

# Reordenar os dados do tempo 1 seguindo a combinação de fatores por cada bloco
blocos_dados_4 <- with(dados_4, 
                             dados_4[order(CICLO, INOCULO, EFLUENTE), ])

# Definir como NA (valor ausente) os outliers
blocos_dados_4$Na[which(blocos_dados_4$Na < 
                                    limites_outliers$LIM_INF)] = NA
blocos_dados_4$Na[which(blocos_dados_4$Na > 
                                    limites_outliers$LIM_SUP)] = NA

# Calcular a média para cada grupo de 4 linhas
media_blocos_4 = aggregate(Na ~ EFLUENTE + INOCULO + CICLO, 
                                 data = blocos_dados_4, FUN = mean)

# Replicar cada linha por 4 vezes
media_blocos_4 = media_blocos_4[rep(row.names(media_blocos_4), 
                                                each = 4), ]

# Redefinir os índices das linhas
rownames(media_blocos_4) <- NULL

# Preencher os NA's com as médias dos 4 blocos para a 
# combinação de fatores específica
blocos_dados_4$Na[which(is.na(blocos_dados_4$Na))] =
  media_blocos_4$Na[which(is.na(blocos_dados_4$Na))]

```

```{r}
# Análises Descritivas
str(blocos_dados_4)
summary(blocos_dados_4)

# Número de observações
with(blocos_dados_4, tapply(Na, list(EFLUENTE, INOCULO), length))
with(blocos_dados_4, tapply(Na, list(EFLUENTE, INOCULO), sum))
with(blocos_dados_4, tapply(Na, list(EFLUENTE, INOCULO), mean))
with(blocos_dados_4, tapply(Na, list(EFLUENTE, INOCULO), var))
with(blocos_dados_4, tapply(Na, list(EFLUENTE, INOCULO), sd))

# Tamanho das Médias
T.medias <- with(blocos_dados_4,
                 model.tables(aov(Na ~ BLOCO + EFLUENTE + INOCULO +
                                    EFLUENTE:INOCULO),
                              "means"))
T.medias
```

```{r}
# Media dos blocos para fazer os testes de Normalidade e Homocedasticidade
media_blocos_4 = aggregate(Na ~ EFLUENTE + INOCULO + CICLO, 
                                 data = blocos_dados_4, FUN = mean)

# Realizar o teste Shapiro-Wilk no conjunto de dados completo
resultado_shapiro <- shapiro.test(media_blocos_4$Na)$p.value

# Exibir o resultado do teste Shapiro-Wilk
print(resultado_shapiro)

# Interpretação do p-valor
if (resultado_shapiro > 0.05) {
  print("Os dados seguem uma distribuição normal.")
} else {
  print("Os dados não seguem uma distribuição normal.")
}
```

```{r}
# Realizar o teste de Bartlett no conjunto de dados completo
resultado_bartlett <- bartlett.test(media_blocos_4$Na, 
                                    media_blocos_4$EFLUENTE, 
                                    media_blocos_4$INOCULO,
                                    media_blocos_4$CICLO)$p.value

# Exibir o resultado do teste de Bartlett
print(resultado_bartlett)

# Interpretação do p-valor
if (resultado_bartlett > 0.05) {
  print("A variância é homogênea entre os grupos.")
} else {
  print("A variância não é homogênea entre os grupos.")
}
```

```{r}
# Ajustar o modelo linear para parcelas subdivididas
modelo_PARCELASUB = aov(Na ~ BLOCO + INOCULO * EFLUENTE + 
                          Error(BLOCO*INOCULO), data = blocos_dados_4)

# Visualizar os resultados do modelo
summary(modelo_PARCELASUB)
modelo = modelo_PARCELASUB
```

```{r}
# Refazer o modelo sem o erro, apenas para facilitar as funções subsequentes
modelo = aov(Na ~ BLOCO + INOCULO * EFLUENTE,
             data = blocos_dados_4)

# Realizar a análise de variância (ANOVA)
anova_result <- anova(modelo)

# Filtrar apenas os fatores significativos ao nível 0.05
fatores_significativos <- anova_result[anova_result$"Pr(>F)" < 0.05, ]

# Exibir as interações significativas
print(fatores_significativos)
```

```{r}
# Vetor com os fatores significativos
nomes_linhas = row.names(fatores_significativos)

# Filtrar apenas as interações
interacoes_significativas <- nomes_linhas[nchar(nomes_linhas) > 8]

# Exibir o resultado
print(interacoes_significativas)
```

```{r}
# Realizar o teste de Tukey para todas as interações significativas
tukey_result <- TukeyHSD(modelo)
```

```{r}
for (i in 1:length(interacoes_significativas)) {
  if (length(interacoes_significativas) == 0){
    break
  }
  interacao = interacoes_significativas[i]
  partes <- strsplit(interacao, split = ":")
  if (nchar(interacao) < 20){
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- 0
  }
  else{
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- partes[[1]][3]
  }
  
  if(fator1 == "INOCULO" && fator2 == "EFLUENTE" && fator3 == 0){
    media_interacao <- aggregate(Na ~ INOCULO + EFLUENTE, 
                             data = blocos_dados_4, FUN = mean)
    print(media_interacao)
  }

}
```

```{r}
for (i in 1:length(interacoes_significativas)) {
  if (length(interacoes_significativas) == 0){
    break
  }
  interacao = interacoes_significativas[i]
  partes <- strsplit(interacao, split = ":")
  if (nchar(interacao) < 20){
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- 0
  }
  else{
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- partes[[1]][3]
  }
  
  inter_tukey = tukey_result[interacao]
  inter_tukey = data.frame(inter_tukey)
  colnames(inter_tukey) = c('diif','lwr','upr','p_adj')
  inter_tukey = subset(inter_tukey, p_adj < 0.05)
  print(inter_tukey)
}
```

### Análise para Cálcio ###

```{r}
# Gráficos com os boxplots para cada combinação de todos os fatores
ggplot(dados_5, aes(x = factor(EFLUENTE), y = Ca)) +
  geom_boxplot() +
  facet_grid(INOCULO ~ CICLO) +
  labs(x = "EFLUENTE", y = "Cálcio") +
  ggtitle("Boxplots por combinação dos fatores")
```

```{r}
# Calcular os limites inferiores de outliers para cada combinação de fatores
limites_outliers <- aggregate(Ca ~ EFLUENTE + INOCULO + CICLO, 
                              data = dados_5, FUN = function(x) {
  q <- quantile(x, c(0.25, 0.75), na.rm = TRUE)
  iqr <- q[2] - q[1]
  limite_inferior <- q[1] - 1.5 * iqr
})

# Armazenar vetor com os limites inferiores
lim_inf = limites_outliers$Ca

# Calcular os limites superiores de outliers para cada combinação de fatores
limites_outliers <- aggregate(Ca ~ EFLUENTE + INOCULO + CICLO, 
                              data = dados_5, FUN = function(x) {
  q <- quantile(x, c(0.25, 0.75), na.rm = TRUE)
  iqr <- q[2] - q[1]
  limite_superior <- q[2] + 1.5 * iqr
})

# Armazenar vetor com os limites superiores
lim_sup = limites_outliers$Ca

# Montar Dataframe com os limites inferior e superior
limites_outliers = limites_outliers[c(1:3)]
limites_outliers$LIM_INF = lim_inf
limites_outliers$LIM_SUP = lim_sup

# Definir o número de replicação de acordo com o valor de CICLO
num_rep <- ifelse(limites_outliers$CICLO == 1, 4, 3)

# Replicar as linhas do dataframe
limites_outliers <- limites_outliers[rep(row.names(limites_outliers), 
                                         num_rep), ]

# Redefinir os índices das linhas
rownames(limites_outliers) <- NULL

# Reordenar os dados do tempo 1 seguindo a combinação de fatores por cada bloco
blocos_dados_5 <- with(dados_5, 
                             dados_5[order(CICLO, INOCULO, EFLUENTE), ])

# Definir como NA (valor ausente) os outliers
blocos_dados_5$Ca[which(blocos_dados_5$Ca < 
                                    limites_outliers$LIM_INF)] = NA
blocos_dados_5$Ca[which(blocos_dados_5$Ca > 
                                    limites_outliers$LIM_SUP)] = NA

# Calcular a média para cada grupo de 4 linhas
media_blocos_5 = aggregate(Ca ~ EFLUENTE + INOCULO + CICLO, 
                                 data = blocos_dados_5, FUN = mean)

# Replicar cada linha por 4 vezes
media_blocos_5 = media_blocos_5[rep(row.names(media_blocos_5), 
                                                each = 4), ]

# Redefinir os índices das linhas
rownames(media_blocos_5) <- NULL

# Preencher os NA's com as médias dos 4 blocos para a 
# combinação de fatores específica
blocos_dados_5$Ca[which(is.na(blocos_dados_5$Ca))] =
  media_blocos_5$Ca[which(is.na(blocos_dados_5$Ca))]

```

```{r}
# Substituir o outlier na linha 37 pela média das amostras de EFLUENTE = 100 e
# INÓCULO = "SEM"
blocos_dados_5$Ca[37] = media_blocos_5$Ca[37]
```

```{r}
# Análises Descritivas
str(blocos_dados_5)
summary(blocos_dados_5)

# Número de observações
with(blocos_dados_5, tapply(Ca, list(EFLUENTE, INOCULO), length))
with(blocos_dados_5, tapply(Ca, list(EFLUENTE, INOCULO), sum))
with(blocos_dados_5, tapply(Ca, list(EFLUENTE, INOCULO), mean))
with(blocos_dados_5, tapply(Ca, list(EFLUENTE, INOCULO), var))
with(blocos_dados_5, tapply(Ca, list(EFLUENTE, INOCULO), sd))

# Tamanho das Médias
T.medias <- with(blocos_dados_5,
                 model.tables(aov(Ca ~ BLOCO + EFLUENTE + INOCULO +
                                    EFLUENTE:INOCULO),
                              "means"))
T.medias
```

```{r}
# Media dos blocos para fazer os testes de Normalidade e Homocedasticidade
media_blocos_5 = aggregate(Ca ~ EFLUENTE + INOCULO + CICLO, 
                                 data = blocos_dados_5, FUN = mean)

# Realizar o teste Shapiro-Wilk no conjunto de dados completo
resultado_shapiro <- shapiro.test(media_blocos_5$Ca)$p.value

# Exibir o resultado do teste Shapiro-Wilk
print(resultado_shapiro)

# Interpretação do p-valor
if (resultado_shapiro > 0.05) {
  print("Os dados seguem uma distribuição normal.")
} else {
  print("Os dados não seguem uma distribuição normal.")
}
```

```{r}
# Realizar o teste de Bartlett no conjunto de dados completo
resultado_bartlett <- bartlett.test(media_blocos_5$Ca, 
                                    media_blocos_5$EFLUENTE, 
                                    media_blocos_5$INOCULO,
                                    media_blocos_5$CICLO)$p.value

# Exibir o resultado do teste de Bartlett
print(resultado_bartlett)

# Interpretação do p-valor
if (resultado_bartlett > 0.05) {
  print("A variância é homogênea entre os grupos.")
} else {
  print("A variância não é homogênea entre os grupos.")
}
```

```{r}
# Ajustar o modelo linear para parcelas subdivididas
modelo_PARCELASUB = aov(Ca ~ BLOCO + INOCULO * EFLUENTE + 
                          Error(BLOCO*INOCULO), data = blocos_dados_5)

# Visualizar os resultados do modelo
summary(modelo_PARCELASUB)
modelo = modelo_PARCELASUB
```

```{r}
# Refazer o modelo sem o erro, apenas para facilitar as funções subsequentes
modelo = aov(Ca ~ BLOCO + INOCULO * EFLUENTE,
             data = blocos_dados_5)

# Realizar a análise de variância (ANOVA)
anova_result <- anova(modelo)

# Filtrar apenas os fatores significativos ao nível 0.05
fatores_significativos <- anova_result[anova_result$"Pr(>F)" < 0.05, ]

# Exibir as interações significativas
print(fatores_significativos)
```

```{r}
# Vetor com os fatores significativos
nomes_linhas = row.names(fatores_significativos)

# Filtrar apenas as interações
interacoes_significativas <- nomes_linhas[nchar(nomes_linhas) > 8]

# Exibir o resultado
print(interacoes_significativas)
```

```{r}
# Realizar o teste de Tukey para todas as interações significativas
tukey_result <- TukeyHSD(modelo)
```

```{r}
for (i in 1:length(interacoes_significativas)) {
  if (length(interacoes_significativas) == 0){
    break
  }
  interacao = interacoes_significativas[i]
  partes <- strsplit(interacao, split = ":")
  if (nchar(interacao) < 20){
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- 0
  }
  else{
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- partes[[1]][3]
  }
  
  if(fator1 == "INOCULO" && fator2 == "EFLUENTE" && fator3 == 0){
    media_interacao <- aggregate(Ca ~ INOCULO + EFLUENTE, 
                             data = blocos_dados_5, FUN = mean)
    print(media_interacao)
  }

}
```

```{r}
for (i in 1:length(interacoes_significativas)) {
  if (length(interacoes_significativas) == 0){
    break
  }
  interacao = interacoes_significativas[i]
  partes <- strsplit(interacao, split = ":")
  if (nchar(interacao) < 20){
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- 0
  }
  else{
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- partes[[1]][3]
  }
  
  inter_tukey = tukey_result[interacao]
  inter_tukey = data.frame(inter_tukey)
  colnames(inter_tukey) = c('diif','lwr','upr','p_adj')
  inter_tukey = subset(inter_tukey, p_adj < 0.05)
  print(inter_tukey)
}
```

### Análise para Magnésio ###

```{r}
# Gráficos com os boxplots para cada combinação de todos os fatores
ggplot(dados_6, aes(x = factor(EFLUENTE), y = Mg)) +
  geom_boxplot() +
  facet_grid(INOCULO ~ CICLO) +
  labs(x = "EFLUENTE", y = "Magnésio") +
  ggtitle("Boxplots por combinação dos fatores")
```

```{r}
# Calcular os limites inferiores de outliers para cada combinação de fatores
limites_outliers <- aggregate(Mg ~ EFLUENTE + INOCULO + CICLO, 
                              data = dados_6, FUN = function(x) {
  q <- quantile(x, c(0.25, 0.75), na.rm = TRUE)
  iqr <- q[2] - q[1]
  limite_inferior <- q[1] - 1.5 * iqr
})

# Armazenar vetor com os limites inferiores
lim_inf = limites_outliers$Mg

# Calcular os limites superiores de outliers para cada combinação de fatores
limites_outliers <- aggregate(Mg ~ EFLUENTE + INOCULO + CICLO, 
                              data = dados_6, FUN = function(x) {
  q <- quantile(x, c(0.25, 0.75), na.rm = TRUE)
  iqr <- q[2] - q[1]
  limite_superior <- q[2] + 1.5 * iqr
})

# Armazenar vetor com os limites superiores
lim_sup = limites_outliers$Mg

# Montar Dataframe com os limites inferior e superior
limites_outliers = limites_outliers[c(1:3)]
limites_outliers$LIM_INF = lim_inf
limites_outliers$LIM_SUP = lim_sup

# Definir o número de replicação de acordo com o valor de CICLO
num_rep <- ifelse(limites_outliers$CICLO == 1, 4, 3)

# Replicar as linhas do dataframe
limites_outliers <- limites_outliers[rep(row.names(limites_outliers), 
                                         num_rep), ]

# Redefinir os índices das linhas
rownames(limites_outliers) <- NULL

# Reordenar os dados do tempo 1 seguindo a combinação de fatores por cada bloco
blocos_dados_6 <- with(dados_6, 
                             dados_6[order(CICLO, INOCULO, EFLUENTE), ])

# Definir como NA (valor ausente) os outliers
blocos_dados_6$Mg[which(blocos_dados_6$Mg < 
                                    limites_outliers$LIM_INF)] = NA
blocos_dados_6$Mg[which(blocos_dados_6$Mg > 
                                    limites_outliers$LIM_SUP)] = NA

# Calcular a média para cada grupo de 4 linhas
media_blocos_6 = aggregate(Mg ~ EFLUENTE + INOCULO + CICLO, 
                                 data = blocos_dados_6, FUN = mean)

# Replicar cada linha por 4 vezes
media_blocos_6 = media_blocos_6[rep(row.names(media_blocos_6), 
                                                each = 4), ]

# Redefinir os índices das linhas
rownames(media_blocos_6) <- NULL

# Preencher os NA's com as médias dos 4 blocos para a 
# combinação de fatores específica
blocos_dados_6$Mg[which(is.na(blocos_dados_6$Mg))] =
  media_blocos_6$Mg[which(is.na(blocos_dados_6$Mg))]
```

```{r}
# Análises Descritivas
str(blocos_dados_6)
summary(blocos_dados_6)

# Número de observações
with(blocos_dados_6, tapply(Mg, list(EFLUENTE, INOCULO), length))
with(blocos_dados_6, tapply(Mg, list(EFLUENTE, INOCULO), sum))
with(blocos_dados_6, tapply(Mg, list(EFLUENTE, INOCULO), mean))
with(blocos_dados_6, tapply(Mg, list(EFLUENTE, INOCULO), var))
with(blocos_dados_6, tapply(Mg, list(EFLUENTE, INOCULO), sd))

# Tamanho das Médias
T.medias <- with(blocos_dados_6,
                 model.tables(aov(Mg ~ BLOCO + EFLUENTE + INOCULO +
                                    EFLUENTE:INOCULO),
                              "means"))
T.medias
```

```{r}
# Media dos blocos para fazer os testes de Normalidade e Homocedasticidade
media_blocos_6 = aggregate(Mg ~ EFLUENTE + INOCULO + CICLO, 
                                 data = blocos_dados_6, FUN = mean)

# Realizar o teste Shapiro-Wilk no conjunto de dados completo
resultado_shapiro <- shapiro.test(media_blocos_6$Mg)$p.value

# Exibir o resultado do teste Shapiro-Wilk
print(resultado_shapiro)

# Interpretação do p-valor
if (resultado_shapiro > 0.05) {
  print("Os dados seguem uma distribuição normal.")
} else {
  print("Os dados não seguem uma distribuição normal.")
}
```

```{r}
# Realizar o teste de Bartlett no conjunto de dados completo
resultado_bartlett <- bartlett.test(media_blocos_6$Mg, 
                                    media_blocos_6$EFLUENTE, 
                                    media_blocos_6$INOCULO,
                                    media_blocos_6$CICLO)$p.value

# Exibir o resultado do teste de Bartlett
print(resultado_bartlett)

# Interpretação do p-valor
if (resultado_bartlett > 0.05) {
  print("A variância é homogênea entre os grupos.")
} else {
  print("A variância não é homogênea entre os grupos.")
}
```

```{r}
# Ajustar o modelo linear para parcelas subdivididas
modelo_PARCELASUB = aov(Mg ~ BLOCO + INOCULO * EFLUENTE + 
                          Error(BLOCO*INOCULO), data = blocos_dados_6)

# Visualizar os resultados do modelo
summary(modelo_PARCELASUB)
modelo = modelo_PARCELASUB
```

```{r}
# Refazer o modelo sem o erro, apenas para facilitar as funções subsequentes
modelo = aov(Mg ~ BLOCO + INOCULO * EFLUENTE,
             data = blocos_dados_6)

# Realizar a análise de variância (ANOVA)
anova_result <- anova(modelo)

# Filtrar apenas os fatores significativos ao nível 0.05
fatores_significativos <- anova_result[anova_result$"Pr(>F)" < 0.05, ]

# Exibir as interações significativas
print(fatores_significativos)
```

```{r}
# Vetor com os fatores significativos
nomes_linhas = row.names(fatores_significativos)

# Filtrar apenas as interações
interacoes_significativas <- nomes_linhas[nchar(nomes_linhas) > 8]

# Exibir o resultado
print(interacoes_significativas)
```

```{r}
# Realizar o teste de Tukey para todas as interações significativas
tukey_result <- TukeyHSD(modelo)
```

```{r}
for (i in 1:length(interacoes_significativas)) {
  if (length(interacoes_significativas) == 0){
    break
  }
  interacao = interacoes_significativas[i]
  partes <- strsplit(interacao, split = ":")
  if (nchar(interacao) < 20){
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- 0
  }
  else{
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- partes[[1]][3]
  }
  
  if(fator1 == "INOCULO" && fator2 == "EFLUENTE" && fator3 == 0){
    media_interacao <- aggregate(Mg ~ INOCULO + EFLUENTE, 
                             data = blocos_dados_6, FUN = mean)
    print(media_interacao)
  }

}
```

```{r}
for (i in 1:length(interacoes_significativas)) {
  if (length(interacoes_significativas) == 0){
    break
  }
  interacao = interacoes_significativas[i]
  partes <- strsplit(interacao, split = ":")
  if (nchar(interacao) < 20){
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- 0
  }
  else{
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- partes[[1]][3]
  }
  
  inter_tukey = tukey_result[interacao]
  inter_tukey = data.frame(inter_tukey)
  colnames(inter_tukey) = c('diif','lwr','upr','p_adj')
  inter_tukey = subset(inter_tukey, p_adj < 0.05)
  print(inter_tukey)
}
```

### Análise para Enxofre ###

```{r}
# Gráficos com os boxplots para cada combinação de todos os fatores
ggplot(dados_7, aes(x = factor(EFLUENTE), y = S)) +
  geom_boxplot() +
  facet_grid(INOCULO ~ CICLO) +
  labs(x = "EFLUENTE", y = "Enxofre") +
  ggtitle("Boxplots por combinação dos fatores")
```

```{r}
# Calcular os limites inferiores de outliers para cada combinação de fatores
limites_outliers <- aggregate(S ~ EFLUENTE + INOCULO + CICLO, 
                              data = dados_7, FUN = function(x) {
  q <- quantile(x, c(0.25, 0.75), na.rm = TRUE)
  iqr <- q[2] - q[1]
  limite_inferior <- q[1] - 1.5 * iqr
})

# Armazenar vetor com os limites inferiores
lim_inf = limites_outliers$S

# Calcular os limites superiores de outliers para cada combinação de fatores
limites_outliers <- aggregate(S ~ EFLUENTE + INOCULO + CICLO, 
                              data = dados_7, FUN = function(x) {
  q <- quantile(x, c(0.25, 0.75), na.rm = TRUE)
  iqr <- q[2] - q[1]
  limite_superior <- q[2] + 1.5 * iqr
})

# Armazenar vetor com os limites superiores
lim_sup = limites_outliers$S

# Montar Dataframe com os limites inferior e superior
limites_outliers = limites_outliers[c(1:3)]
limites_outliers$LIM_INF = lim_inf
limites_outliers$LIM_SUP = lim_sup

# Definir o número de replicação de acordo com o valor de CICLO
num_rep <- ifelse(limites_outliers$CICLO == 1, 4, 3)

# Replicar as linhas do dataframe
limites_outliers <- limites_outliers[rep(row.names(limites_outliers), 
                                         num_rep), ]

# Redefinir os índices das linhas
rownames(limites_outliers) <- NULL

# Reordenar os dados do tempo 1 seguindo a combinação de fatores por cada bloco
blocos_dados_7 <- with(dados_7, 
                             dados_7[order(CICLO, INOCULO, EFLUENTE), ])

# Definir como NA (valor ausente) os outliers
blocos_dados_7$S[which(blocos_dados_7$S < 
                                    limites_outliers$LIM_INF)] = NA
blocos_dados_7$S[which(blocos_dados_7$S > 
                                    limites_outliers$LIM_SUP)] = NA

# Calcular a média para cada grupo de 4 linhas
media_blocos_7 = aggregate(S ~ EFLUENTE + INOCULO + CICLO, 
                                 data = blocos_dados_7, FUN = mean)

# Replicar cada linha por 4 vezes
media_blocos_7 = media_blocos_7[rep(row.names(media_blocos_7), 
                                                each = 4), ]

# Redefinir os índices das linhas
rownames(media_blocos_7) <- NULL

# Preencher os NA's com as médias dos 4 blocos para a 
# combinação de fatores específica
blocos_dados_7$S[which(is.na(blocos_dados_7$S))] =
  media_blocos_7$S[which(is.na(blocos_dados_7$S))]
```

```{r}
# Análises Descritivas
str(blocos_dados_7)
summary(blocos_dados_7)

# Número de observações
with(blocos_dados_7, tapply(S, list(EFLUENTE, INOCULO), length))
with(blocos_dados_7, tapply(S, list(EFLUENTE, INOCULO), sum))
with(blocos_dados_7, tapply(S, list(EFLUENTE, INOCULO), mean))
with(blocos_dados_7, tapply(S, list(EFLUENTE, INOCULO), var))
with(blocos_dados_7, tapply(S, list(EFLUENTE, INOCULO), sd))

# Tamanho das Médias
T.medias <- with(blocos_dados_7,
                 model.tables(aov(S ~ BLOCO + EFLUENTE + INOCULO +
                                    EFLUENTE:INOCULO),
                              "means"))
T.medias
```

```{r}
# Media dos blocos para fazer os testes de Normalidade e Homocedasticidade
media_blocos_7 = aggregate(S ~ EFLUENTE + INOCULO + CICLO, 
                                 data = blocos_dados_7, FUN = mean)

# Realizar o teste Shapiro-Wilk no conjunto de dados completo
resultado_shapiro <- shapiro.test(media_blocos_7$S)$p.value

# Exibir o resultado do teste Shapiro-Wilk
print(resultado_shapiro)

# Interpretação do p-valor
if (resultado_shapiro > 0.05) {
  print("Os dados seguem uma distribuição normal.")
} else {
  print("Os dados não seguem uma distribuição normal.")
}
```

```{r}
# Realizar o teste de Bartlett no conjunto de dados completo
resultado_bartlett <- bartlett.test(media_blocos_7$S, 
                                    media_blocos_7$EFLUENTE, 
                                    media_blocos_7$INOCULO,
                                    media_blocos_7$CICLO)$p.value

# Exibir o resultado do teste de Bartlett
print(resultado_bartlett)

# Interpretação do p-valor
if (resultado_bartlett > 0.05) {
  print("A variância é homogênea entre os grupos.")
} else {
  print("A variância não é homogênea entre os grupos.")
}
```

```{r}
# Ajustar o modelo linear para parcelas subdivididas
modelo_PARCELASUB = aov(S ~ BLOCO + INOCULO * EFLUENTE + 
                          Error(BLOCO*INOCULO), data = blocos_dados_7)

# Visualizar os resultados do modelo
summary(modelo_PARCELASUB)
modelo = modelo_PARCELASUB
```

```{r}
# Refazer o modelo sem o erro, apenas para facilitar as funções subsequentes
modelo = aov(S ~ BLOCO + INOCULO * EFLUENTE,
             data = blocos_dados_7)

# Realizar a análise de variância (ANOVA)
anova_result <- anova(modelo)

# Filtrar apenas os fatores significativos ao nível 0.05
fatores_significativos <- anova_result[anova_result$"Pr(>F)" < 0.05, ]

# Exibir as interações significativas
print(fatores_significativos)
```

```{r}
# Vetor com os fatores significativos
nomes_linhas = row.names(fatores_significativos)

# Filtrar apenas as interações
interacoes_significativas <- nomes_linhas[nchar(nomes_linhas) > 8]

# Exibir o resultado
print(interacoes_significativas)
```

```{r}
# Realizar o teste de Tukey para todas as interações significativas
tukey_result <- TukeyHSD(modelo)
```

```{r}
for (i in 1:length(interacoes_significativas)) {
  if (length(interacoes_significativas) == 0){
    break
  }
  interacao = interacoes_significativas[i]
  partes <- strsplit(interacao, split = ":")
  if (nchar(interacao) < 20){
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- 0
  }
  else{
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- partes[[1]][3]
  }
  
  if(fator1 == "INOCULO" && fator2 == "EFLUENTE" && fator3 == 0){
    media_interacao <- aggregate(S ~ INOCULO + EFLUENTE, 
                             data = blocos_dados_7, FUN = mean)
    print(media_interacao)
  }

}
```

```{r}
for (i in 1:length(interacoes_significativas)) {
  if (length(interacoes_significativas) == 0){
    break
  }
  interacao = interacoes_significativas[i]
  partes <- strsplit(interacao, split = ":")
  if (nchar(interacao) < 20){
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- 0
  }
  else{
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- partes[[1]][3]
  }
  
  inter_tukey = tukey_result[interacao]
  inter_tukey = data.frame(inter_tukey)
  colnames(inter_tukey) = c('diif','lwr','upr','p_adj')
  inter_tukey = subset(inter_tukey, p_adj < 0.05)
  print(inter_tukey)
}
```

```{r}
# Juntar dados em um mesmo dataframe
dados_final = cbind(blocos_dados_1, blocos_dados_2["P"], 
                    blocos_dados_3["K"], blocos_dados_4["Na"],
                    blocos_dados_5["Ca"], blocos_dados_6["Mg"],
                    blocos_dados_7["S"])


# Criar planilha com todos os dados atualizados
library("xlsx")
write.xlsx(dados_final, file = "Foliar atualizado - Ciclo 1.xlsx",
      sheetName = "R - Foliar_1", append = FALSE)
```

### CICLO 2 ###

```{r}
# Leitura e tratamento dos dados
dados <- read_excel("Foliar ok.xlsx")

# Ordenar o dataframe por quatro colunas diferentes
dados <- with(dados, dados[order(CICLO, BLOCO, EFLUENTE, INOCULO), ])

# Converter as colunas para tipo numérico e arredondar valores em duas casas
for (i in 5:7) {
  dados[, i] <- as.numeric(unlist(dados[, i]))
}
dados[5:7] =  round(dados[5:7], digits = 2)
str(dados)
```

```{r}
# Transformar as colunas em variáveis categóricas
dados$BLOCO <- factor(dados$BLOCO)
dados$CICLO <- factor(dados$CICLO)
dados$INOCULO <- factor(dados$INOCULO)
dados$EFLUENTE <- factor(dados$EFLUENTE)
```

```{r}
# Usar apenas dados do Ciclo 2
dados = subset(dados, CICLO == 2)
```

```{r}
# Separar os dados de acordo com o período de tempo da coleta
dados_1 = dados[c(1:5)]
dados_2 = dados[c(1:4,6)]
dados_3 = dados[c(1:4,7)]
dados_4 = dados[c(1:4,8)]
dados_5 = dados[c(1:4,9)]
dados_6 = dados[c(1:4,10)]
dados_7 = dados[c(1:4,11)]

# Estrutura dos dados após separados
"dados_1"
str(dados_1)
"dados_2"
str(dados_2)
"dados_3"
str(dados_3)
"dados_4"
str(dados_4)
"dados_5"
str(dados_5)
"dados_6"
str(dados_5)
"dados_7"
str(dados_5)
```

### Análise para Nitrogênio ###

```{r}
# Gráficos com os boxplots para cada combinação de todos os fatores
ggplot(dados_1, aes(x = factor(EFLUENTE), y = N)) +
  geom_boxplot() +
  facet_grid(INOCULO ~ CICLO) +
  labs(x = "EFLUENTE", y = "Nitrogênio") +
  ggtitle("Boxplots por combinação dos fatores")
```

```{r}
# Calcular os limites inferiores de outliers para cada combinação de fatores
limites_outliers <- aggregate(N ~ EFLUENTE + INOCULO + CICLO, 
                              data = dados_1, FUN = function(x) {
  q <- quantile(x, c(0.25, 0.75), na.rm = TRUE)
  iqr <- q[2] - q[1]
  limite_inferior <- q[1] - 1.5 * iqr
})

# Armazenar vetor com os limites inferiores
lim_inf = limites_outliers$N

# Calcular os limites superiores de outliers para cada combinação de fatores
limites_outliers <- aggregate(N ~ EFLUENTE + INOCULO + CICLO, 
                              data = dados_1, FUN = function(x) {
  q <- quantile(x, c(0.25, 0.75), na.rm = TRUE)
  iqr <- q[2] - q[1]
  limite_superior <- q[2] + 1.5 * iqr
})

# Armazenar vetor com os limites superiores
lim_sup = limites_outliers$N

# Montar Dataframe com os limites inferior e superior
limites_outliers = limites_outliers[c(1:3)]
limites_outliers$LIM_INF = lim_inf
limites_outliers$LIM_SUP = lim_sup

# Definir o número de replicação de acordo com o valor de CICLO
num_rep <- ifelse(limites_outliers$CICLO == 1, 4, 3)

# Replicar as linhas do dataframe
limites_outliers <- limites_outliers[rep(row.names(limites_outliers), 
                                         num_rep), ]

# Redefinir os índices das linhas
rownames(limites_outliers) <- NULL

# Reordenar os dados do tempo 1 seguindo a combinação de fatores por cada bloco
blocos_dados_1 <- with(dados_1, 
                             dados_1[order(CICLO, INOCULO, EFLUENTE), ])

# Definir como NA (valor ausente) os outliers
blocos_dados_1$N[which(blocos_dados_1$N < 
                                    limites_outliers$LIM_INF)] = NA
blocos_dados_1$N[which(blocos_dados_1$N > 
                                    limites_outliers$LIM_SUP)] = NA

# Calcular a média para cada grupo de 4 linhas
media_blocos_1 = aggregate(N ~ EFLUENTE + INOCULO + CICLO, 
                                 data = blocos_dados_1, FUN = mean)

# Replicar cada linha por 4 vezes
media_blocos_1 = media_blocos_1[rep(row.names(media_blocos_1), 
                                                each = 4), ]

# Redefinir os índices das linhas
rownames(media_blocos_1) <- NULL

# Preencher os NA's com as médias dos 4 blocos para a 
# combinação de fatores específica
blocos_dados_1$N[which(is.na(blocos_dados_1$N))] =
  media_blocos_1$N[which(is.na(blocos_dados_1$N))]
```


```{r}
# Análises Descritivas
str(blocos_dados_1)
summary(blocos_dados_1)

# Número de observações
with(blocos_dados_1, tapply(N, list(EFLUENTE, INOCULO), length))
with(blocos_dados_1, tapply(N, list(EFLUENTE, INOCULO), sum))
with(blocos_dados_1, tapply(N, list(EFLUENTE, INOCULO), mean))
with(blocos_dados_1, tapply(N, list(EFLUENTE, INOCULO), var))
with(blocos_dados_1, tapply(N, list(EFLUENTE, INOCULO), sd))

# Tamanho das Médias
T.medias <- with(blocos_dados_1,
                 model.tables(aov(N ~ BLOCO + EFLUENTE + INOCULO +
                                    EFLUENTE:INOCULO),
                              "means"))
T.medias
```

```{r}
# Media dos blocos para fazer os testes de Normalidade e Homocedasticidade
media_blocos_1 = aggregate(N ~ EFLUENTE + INOCULO + CICLO, 
                                 data = blocos_dados_1, FUN = mean)

# Realizar o teste Shapiro-Wilk no conjunto de dados completo
resultado_shapiro <- shapiro.test(media_blocos_1$N)$p.value

# Exibir o resultado do teste Shapiro-Wilk
print(resultado_shapiro)

# Interpretação do p-valor
if (resultado_shapiro > 0.05) {
  print("Os dados seguem uma distribuição normal.")
} else {
  print("Os dados não seguem uma distribuição normal.")
}
```

```{r}
# Realizar o teste de Bartlett no conjunto de dados completo
resultado_bartlett <- bartlett.test(media_blocos_1$N, 
                                    media_blocos_1$EFLUENTE, 
                                    media_blocos_1$INOCULO,
                                    media_blocos_1$CICLO)$p.value

# Exibir o resultado do teste de Bartlett
print(resultado_bartlett)

# Interpretação do p-valor
if (resultado_bartlett > 0.05) {
  print("A variância é homogênea entre os grupos.")
} else {
  print("A variância não é homogênea entre os grupos.")
}
```


```{r}
# Ajustar o modelo linear para parcelas subdivididas
modelo_PARCELASUB = aov(N ~ BLOCO + INOCULO * EFLUENTE + 
                          Error(BLOCO*INOCULO), data = blocos_dados_1)

# Visualizar os resultados do modelo
summary(modelo_PARCELASUB)
modelo = modelo_PARCELASUB
```

```{r}
# Refazer o modelo sem o erro, apenas para facilitar as funções subsequentes
modelo = aov(N ~ BLOCO + INOCULO * EFLUENTE,
             data = blocos_dados_1)

# Realizar a análise de variância (ANOVA)
anova_result <- anova(modelo)

# Filtrar apenas os fatores significativos ao nível 0.05
fatores_significativos <- anova_result[anova_result$"Pr(>F)" < 0.05, ]

# Exibir as interações significativas
print(fatores_significativos)
```

```{r}
# Vetor com os fatores significativos
nomes_linhas = row.names(fatores_significativos)

# Filtrar apenas as interações
interacoes_significativas <- nomes_linhas[nchar(nomes_linhas) > 8]

# Exibir o resultado
print(interacoes_significativas)
```

```{r}
# Realizar o teste de Tukey para todas as interações significativas
tukey_result <- TukeyHSD(modelo)
```

```{r}
for (i in 1:length(interacoes_significativas)) {
  if (length(interacoes_significativas) == 0){
    break
  }
  interacao = interacoes_significativas[i]
  partes <- strsplit(interacao, split = ":")
  if (nchar(interacao) < 20){
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- 0
  }
  else{
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- partes[[1]][3]
  }
  
  if(fator1 == "INOCULO" && fator2 == "EFLUENTE" && fator3 == 0){
    media_interacao <- aggregate(N ~ INOCULO + EFLUENTE, 
                             data = blocos_dados_1, FUN = mean)
    print(media_interacao)
  }

}
```

```{r}
for (i in 1:length(interacoes_significativas)) {
  if (length(interacoes_significativas) == 0){
    break
  }
  interacao = interacoes_significativas[i]
  partes <- strsplit(interacao, split = ":")
  if (nchar(interacao) < 20){
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- 0
  }
  else{
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- partes[[1]][3]
  }
  
  inter_tukey = tukey_result[interacao]
  inter_tukey = data.frame(inter_tukey)
  colnames(inter_tukey) = c('diif','lwr','upr','p_adj')
  inter_tukey = subset(inter_tukey, p_adj < 0.05)
  print(inter_tukey)
}
```

### Análise para Fósforo ###

```{r}
# Gráficos com os boxplots para cada combinação de todos os fatores
ggplot(dados_2, aes(x = factor(EFLUENTE), y = P)) +
  geom_boxplot() +
  facet_grid(INOCULO ~ CICLO) +
  labs(x = "EFLUENTE", y = "Fósforo") +
  ggtitle("Boxplots por combinação dos fatores")
```

```{r}
# Calcular os limites inferiores de outliers para cada combinação de fatores
limites_outliers <- aggregate(P ~ EFLUENTE + INOCULO + CICLO, 
                              data = dados_2, FUN = function(x) {
  q <- quantile(x, c(0.25, 0.75), na.rm = TRUE)
  iqr <- q[2] - q[1]
  limite_inferior <- q[1] - 1.5 * iqr
})

# Armazenar vetor com os limites inferiores
lim_inf = limites_outliers$P

# Calcular os limites superiores de outliers para cada combinação de fatores
limites_outliers <- aggregate(P ~ EFLUENTE + INOCULO + CICLO, 
                              data = dados_2, FUN = function(x) {
  q <- quantile(x, c(0.25, 0.75), na.rm = TRUE)
  iqr <- q[2] - q[1]
  limite_superior <- q[2] + 1.5 * iqr
})

# Armazenar vetor com os limites superiores
lim_sup = limites_outliers$P

# Montar Dataframe com os limites inferior e superior
limites_outliers = limites_outliers[c(1:3)]
limites_outliers$LIM_INF = lim_inf
limites_outliers$LIM_SUP = lim_sup

# Definir o número de replicação de acordo com o valor de CICLO
num_rep <- ifelse(limites_outliers$CICLO == 1, 4, 3)

# Replicar as linhas do dataframe
limites_outliers <- limites_outliers[rep(row.names(limites_outliers), 
                                         num_rep), ]

# Redefinir os índices das linhas
rownames(limites_outliers) <- NULL

# Reordenar os dados do tempo 1 seguindo a combinação de fatores por cada bloco
blocos_dados_2 <- with(dados_2, 
                             dados_2[order(CICLO, INOCULO, EFLUENTE), ])

# Definir como NA (valor ausente) os outliers
blocos_dados_2$P[which(blocos_dados_2$P < 
                                    limites_outliers$LIM_INF)] = NA
blocos_dados_2$P[which(blocos_dados_2$P > 
                                    limites_outliers$LIM_SUP)] = NA

# Calcular a média para cada grupo de 4 linhas
media_blocos_2 = aggregate(P ~ EFLUENTE + INOCULO + CICLO, 
                                 data = blocos_dados_2, FUN = mean)

# Replicar cada linha por 4 vezes
media_blocos_2 = media_blocos_2[rep(row.names(media_blocos_2), 
                                                each = 4), ]

# Redefinir os índices das linhas
rownames(media_blocos_2) <- NULL

# Preencher os NA's com as médias dos 4 blocos para a 
# combinação de fatores específica
blocos_dados_2$P[which(is.na(blocos_dados_2$P))] =
  media_blocos_2$P[which(is.na(blocos_dados_2$P))]

```

```{r}
# Análises Descritivas
str(blocos_dados_2)
summary(blocos_dados_2)

# Número de observações
with(blocos_dados_2, tapply(P, list(EFLUENTE, INOCULO), length))
with(blocos_dados_2, tapply(P, list(EFLUENTE, INOCULO), sum))
with(blocos_dados_2, tapply(P, list(EFLUENTE, INOCULO), mean))
with(blocos_dados_2, tapply(P, list(EFLUENTE, INOCULO), var))
with(blocos_dados_2, tapply(P, list(EFLUENTE, INOCULO), sd))

# Tamanho das Médias
T.medias <- with(blocos_dados_2,
                 model.tables(aov(P ~ BLOCO + EFLUENTE + INOCULO +
                                    EFLUENTE:INOCULO),
                              "means"))
T.medias
```

```{r}
# Media dos blocos para fazer os testes de Normalidade e Homocedasticidade
media_blocos_2 = aggregate(P ~ EFLUENTE + INOCULO + CICLO, 
                                 data = blocos_dados_2, FUN = mean)

# Realizar o teste Shapiro-Wilk no conjunto de dados completo
resultado_shapiro <- shapiro.test(media_blocos_2$P)$p.value

# Exibir o resultado do teste Shapiro-Wilk
print(resultado_shapiro)

# Interpretação do p-valor
if (resultado_shapiro > 0.05) {
  print("Os dados seguem uma distribuição normal.")
} else {
  print("Os dados não seguem uma distribuição normal.")
}
```

```{r}
# Realizar o teste de Bartlett no conjunto de dados completo
resultado_bartlett <- bartlett.test(media_blocos_2$P, 
                                    media_blocos_2$EFLUENTE, 
                                    media_blocos_2$INOCULO,
                                    media_blocos_2$CICLO)$p.value

# Exibir o resultado do teste de Bartlett
print(resultado_bartlett)

# Interpretação do p-valor
if (resultado_bartlett > 0.05) {
  print("A variância é homogênea entre os grupos.")
} else {
  print("A variância não é homogênea entre os grupos.")
}
```

```{r}
# Ajustar o modelo linear para parcelas subdivididas
modelo_PARCELASUB = aov(P ~ BLOCO + INOCULO * EFLUENTE + 
                          Error(BLOCO*INOCULO), data = blocos_dados_2)

# Visualizar os resultados do modelo
summary(modelo_PARCELASUB)
modelo = modelo_PARCELASUB
```

```{r}
# Refazer o modelo sem o erro, apenas para facilitar as funções subsequentes
modelo = aov(P ~ BLOCO + INOCULO * EFLUENTE,
             data = blocos_dados_2)

# Realizar a análise de variância (ANOVA)
anova_result <- anova(modelo)

# Filtrar apenas os fatores significativos ao nível 0.05
fatores_significativos <- anova_result[anova_result$"Pr(>F)" < 0.05, ]

# Exibir as interações significativas
print(fatores_significativos)
```

```{r}
# Vetor com os fatores significativos
nomes_linhas = row.names(fatores_significativos)

# Filtrar apenas as interações
interacoes_significativas <- nomes_linhas[nchar(nomes_linhas) > 8]

# Exibir o resultado
print(interacoes_significativas)
```

```{r}
# Realizar o teste de Tukey para todas as interações significativas
tukey_result <- TukeyHSD(modelo)
```

```{r}
for (i in 1:length(interacoes_significativas)) {
  if (length(interacoes_significativas) == 0){
    break
  }
  interacao = interacoes_significativas[i]
  partes <- strsplit(interacao, split = ":")
  if (nchar(interacao) < 20){
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- 0
  }
  else{
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- partes[[1]][3]
  }
  
  if(fator1 == "INOCULO" && fator2 == "EFLUENTE" && fator3 == 0){
    media_interacao <- aggregate(P ~ INOCULO + EFLUENTE, 
                             data = blocos_dados_2, FUN = mean)
    print(media_interacao)
  }

}
```

```{r}
for (i in 1:length(interacoes_significativas)) {
  if (length(interacoes_significativas) == 0){
    break
  }
  interacao = interacoes_significativas[i]
  partes <- strsplit(interacao, split = ":")
  if (nchar(interacao) < 20){
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- 0
  }
  else{
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- partes[[1]][3]
  }
  
  inter_tukey = tukey_result[interacao]
  inter_tukey = data.frame(inter_tukey)
  colnames(inter_tukey) = c('diif','lwr','upr','p_adj')
  inter_tukey = subset(inter_tukey, p_adj < 0.05)
  print(inter_tukey)
}
```

### Análise para Potássio ###

```{r}
# Gráficos com os boxplots para cada combinação de todos os fatores
ggplot(dados_3, aes(x = factor(EFLUENTE), y = K)) +
  geom_boxplot() +
  facet_grid(INOCULO ~ CICLO) +
  labs(x = "EFLUENTE", y = "Potássio") +
  ggtitle("Boxplots por combinação dos fatores")
```

```{r}
# Calcular os limites inferiores de outliers para cada combinação de fatores
limites_outliers <- aggregate(K ~ EFLUENTE + INOCULO + CICLO, 
                              data = dados_3, FUN = function(x) {
  q <- quantile(x, c(0.25, 0.75), na.rm = TRUE)
  iqr <- q[2] - q[1]
  limite_inferior <- q[1] - 1.5 * iqr
})

# Armazenar vetor com os limites inferiores
lim_inf = limites_outliers$K

# Calcular os limites superiores de outliers para cada combinação de fatores
limites_outliers <- aggregate(K ~ EFLUENTE + INOCULO + CICLO, 
                              data = dados_3, FUN = function(x) {
  q <- quantile(x, c(0.25, 0.75), na.rm = TRUE)
  iqr <- q[2] - q[1]
  limite_superior <- q[2] + 1.5 * iqr
})

# Armazenar vetor com os limites superiores
lim_sup = limites_outliers$K

# Montar Dataframe com os limites inferior e superior
limites_outliers = limites_outliers[c(1:3)]
limites_outliers$LIM_INF = lim_inf
limites_outliers$LIM_SUP = lim_sup

# Definir o número de replicação de acordo com o valor de CICLO
num_rep <- ifelse(limites_outliers$CICLO == 1, 4, 3)

# Replicar as linhas do dataframe
limites_outliers <- limites_outliers[rep(row.names(limites_outliers), 
                                         num_rep), ]

# Redefinir os índices das linhas
rownames(limites_outliers) <- NULL

# Reordenar os dados do tempo 1 seguindo a combinação de fatores por cada bloco
blocos_dados_3 <- with(dados_3, 
                             dados_3[order(CICLO, INOCULO, EFLUENTE), ])

# Definir como NA (valor ausente) os outliers
blocos_dados_3$K[which(blocos_dados_3$K < 
                                    limites_outliers$LIM_INF)] = NA
blocos_dados_3$K[which(blocos_dados_3$K > 
                                    limites_outliers$LIM_SUP)] = NA

# Calcular a média para cada grupo de 4 linhas
media_blocos_3 = aggregate(K ~ EFLUENTE + INOCULO + CICLO, 
                                 data = blocos_dados_3, FUN = mean)

# Replicar cada linha por 4 vezes
media_blocos_3 = media_blocos_3[rep(row.names(media_blocos_3), 
                                                each = 4), ]

# Redefinir os índices das linhas
rownames(media_blocos_3) <- NULL

# Preencher os NA's com as médias dos 4 blocos para a 
# combinação de fatores específica
blocos_dados_3$K[which(is.na(blocos_dados_3$K))] =
  media_blocos_3$K[which(is.na(blocos_dados_3$K))]

```

```{r}
# Análises Descritivas
str(blocos_dados_3)
summary(blocos_dados_3)

# Número de observações
with(blocos_dados_3, tapply(K, list(EFLUENTE, INOCULO), length))
with(blocos_dados_3, tapply(K, list(EFLUENTE, INOCULO), sum))
with(blocos_dados_3, tapply(K, list(EFLUENTE, INOCULO), mean))
with(blocos_dados_3, tapply(K, list(EFLUENTE, INOCULO), var))
with(blocos_dados_3, tapply(K, list(EFLUENTE, INOCULO), sd))

# Tamanho das Médias
T.medias <- with(blocos_dados_3,
                 model.tables(aov(K ~ BLOCO + EFLUENTE + INOCULO +
                                    EFLUENTE:INOCULO),
                              "means"))
T.medias
```

```{r}
# Media dos blocos para fazer os testes de Normalidade e Homocedasticidade
media_blocos_3 = aggregate(K ~ EFLUENTE + INOCULO + CICLO, 
                                 data = blocos_dados_3, FUN = mean)

# Realizar o teste Shapiro-Wilk no conjunto de dados completo
resultado_shapiro <- shapiro.test(media_blocos_3$K)$p.value

# Exibir o resultado do teste Shapiro-Wilk
print(resultado_shapiro)

# Interpretação do p-valor
if (resultado_shapiro > 0.05) {
  print("Os dados seguem uma distribuição normal.")
} else {
  print("Os dados não seguem uma distribuição normal.")
}
```
```{r}
# Realizar o teste de Bartlett no conjunto de dados completo
resultado_bartlett <- bartlett.test(media_blocos_3$K, 
                                    media_blocos_3$EFLUENTE, 
                                    media_blocos_3$INOCULO,
                                    media_blocos_3$CICLO)$p.value

# Exibir o resultado do teste de Bartlett
print(resultado_bartlett)

# Interpretação do p-valor
if (resultado_bartlett > 0.05) {
  print("A variância é homogênea entre os grupos.")
} else {
  print("A variância não é homogênea entre os grupos.")
}
```

```{r}
# Ajustar o modelo linear para parcelas subdivididas
modelo_PARCELASUB = aov(K ~ BLOCO + INOCULO * EFLUENTE + 
                          Error(BLOCO*INOCULO), data = blocos_dados_3)

# Visualizar os resultados do modelo
summary(modelo_PARCELASUB)
modelo = modelo_PARCELASUB
```

```{r}
# Refazer o modelo sem o erro, apenas para facilitar as funções subsequentes
modelo = aov(K ~ BLOCO + INOCULO * EFLUENTE,
             data = blocos_dados_3)

# Realizar a análise de variância (ANOVA)
anova_result <- anova(modelo)

# Filtrar apenas os fatores significativos ao nível 0.05
fatores_significativos <- anova_result[anova_result$"Pr(>F)" < 0.05, ]

# Exibir as interações significativas
print(fatores_significativos)
```

```{r}
# Vetor com os fatores significativos
nomes_linhas = row.names(fatores_significativos)

# Filtrar apenas as interações
interacoes_significativas <- nomes_linhas[nchar(nomes_linhas) > 8]

# Exibir o resultado
print(interacoes_significativas)
```

```{r}
# Realizar o teste de Tukey para todas as interações significativas
tukey_result <- TukeyHSD(modelo)
```

```{r}
for (i in 1:length(interacoes_significativas)) {
  if (length(interacoes_significativas) == 0){
    break
  }
  interacao = interacoes_significativas[i]
  partes <- strsplit(interacao, split = ":")
  if (nchar(interacao) < 20){
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- 0
  }
  else{
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- partes[[1]][3]
  }
  
  if(fator1 == "INOCULO" && fator2 == "EFLUENTE" && fator3 == 0){
    media_interacao <- aggregate(K ~ INOCULO + EFLUENTE, 
                             data = blocos_dados_3, FUN = mean)
    print(media_interacao)
  }

}
```

```{r}
for (i in 1:length(interacoes_significativas)) {
  if (length(interacoes_significativas) == 0){
    break
  }
  interacao = interacoes_significativas[i]
  partes <- strsplit(interacao, split = ":")
  if (nchar(interacao) < 20){
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- 0
  }
  else{
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- partes[[1]][3]
  }
  
  inter_tukey = tukey_result[interacao]
  inter_tukey = data.frame(inter_tukey)
  colnames(inter_tukey) = c('diif','lwr','upr','p_adj')
  inter_tukey = subset(inter_tukey, p_adj < 0.05)
  print(inter_tukey)
}
```

### Análise para Sódio ###

```{r}
# Gráficos com os boxplots para cada combinação de todos os fatores
ggplot(dados_4, aes(x = factor(EFLUENTE), y = Na)) +
  geom_boxplot() +
  facet_grid(INOCULO ~ CICLO) +
  labs(x = "EFLUENTE", y = "Na") +
  ggtitle("Boxplots por combinação dos fatores")
```

```{r}
# Calcular os limites inferiores de outliers para cada combinação de fatores
limites_outliers <- aggregate(Na ~ EFLUENTE + INOCULO + CICLO, 
                              data = dados_4, FUN = function(x) {
  q <- quantile(x, c(0.25, 0.75), na.rm = TRUE)
  iqr <- q[2] - q[1]
  limite_inferior <- q[1] - 1.5 * iqr
})

# Armazenar vetor com os limites inferiores
lim_inf = limites_outliers$Na

# Calcular os limites superiores de outliers para cada combinação de fatores
limites_outliers <- aggregate(Na ~ EFLUENTE + INOCULO + CICLO, 
                              data = dados_4, FUN = function(x) {
  q <- quantile(x, c(0.25, 0.75), na.rm = TRUE)
  iqr <- q[2] - q[1]
  limite_superior <- q[2] + 1.5 * iqr
})

# Armazenar vetor com os limites superiores
lim_sup = limites_outliers$Na

# Montar Dataframe com os limites inferior e superior
limites_outliers = limites_outliers[c(1:3)]
limites_outliers$LIM_INF = lim_inf
limites_outliers$LIM_SUP = lim_sup

# Definir o número de replicação de acordo com o valor de CICLO
num_rep <- ifelse(limites_outliers$CICLO == 1, 4, 3)

# Replicar as linhas do dataframe
limites_outliers <- limites_outliers[rep(row.names(limites_outliers), 
                                         num_rep), ]

# Redefinir os índices das linhas
rownames(limites_outliers) <- NULL

# Reordenar os dados do tempo 1 seguindo a combinação de fatores por cada bloco
blocos_dados_4 <- with(dados_4, 
                             dados_4[order(CICLO, INOCULO, EFLUENTE), ])

# Definir como NA (valor ausente) os outliers
blocos_dados_4$Na[which(blocos_dados_4$Na < 
                                    limites_outliers$LIM_INF)] = NA
blocos_dados_4$Na[which(blocos_dados_4$Na > 
                                    limites_outliers$LIM_SUP)] = NA

# Calcular a média para cada grupo de 4 linhas
media_blocos_4 = aggregate(Na ~ EFLUENTE + INOCULO + CICLO, 
                                 data = blocos_dados_4, FUN = mean)

# Replicar cada linha por 4 vezes
media_blocos_4 = media_blocos_4[rep(row.names(media_blocos_4), 
                                                each = 4), ]

# Redefinir os índices das linhas
rownames(media_blocos_4) <- NULL

# Preencher os NA's com as médias dos 4 blocos para a 
# combinação de fatores específica
blocos_dados_4$Na[which(is.na(blocos_dados_4$Na))] =
  media_blocos_4$Na[which(is.na(blocos_dados_4$Na))]

```

```{r}
# Análises Descritivas
str(blocos_dados_4)
summary(blocos_dados_4)

# Número de observações
with(blocos_dados_4, tapply(Na, list(EFLUENTE, INOCULO), length))
with(blocos_dados_4, tapply(Na, list(EFLUENTE, INOCULO), sum))
with(blocos_dados_4, tapply(Na, list(EFLUENTE, INOCULO), mean))
with(blocos_dados_4, tapply(Na, list(EFLUENTE, INOCULO), var))
with(blocos_dados_4, tapply(Na, list(EFLUENTE, INOCULO), sd))

# Tamanho das Médias
T.medias <- with(blocos_dados_4,
                 model.tables(aov(Na ~ BLOCO + EFLUENTE + INOCULO +
                                    EFLUENTE:INOCULO),
                              "means"))
T.medias
```

```{r}
# Media dos blocos para fazer os testes de Normalidade e Homocedasticidade
media_blocos_4 = aggregate(Na ~ EFLUENTE + INOCULO + CICLO, 
                                 data = blocos_dados_4, FUN = mean)

# Realizar o teste Shapiro-Wilk no conjunto de dados completo
resultado_shapiro <- shapiro.test(media_blocos_4$Na)$p.value

# Exibir o resultado do teste Shapiro-Wilk
print(resultado_shapiro)

# Interpretação do p-valor
if (resultado_shapiro > 0.05) {
  print("Os dados seguem uma distribuição normal.")
} else {
  print("Os dados não seguem uma distribuição normal.")
}
```

```{r}
# Realizar o teste de Bartlett no conjunto de dados completo
resultado_bartlett <- bartlett.test(media_blocos_4$Na, 
                                    media_blocos_4$EFLUENTE, 
                                    media_blocos_4$INOCULO,
                                    media_blocos_4$CICLO)$p.value

# Exibir o resultado do teste de Bartlett
print(resultado_bartlett)

# Interpretação do p-valor
if (resultado_bartlett > 0.05) {
  print("A variância é homogênea entre os grupos.")
} else {
  print("A variância não é homogênea entre os grupos.")
}
```

```{r}
# Ajustar o modelo linear para parcelas subdivididas
modelo_PARCELASUB = aov(Na ~ BLOCO + INOCULO * EFLUENTE + 
                          Error(BLOCO*INOCULO), data = blocos_dados_4)

# Visualizar os resultados do modelo
summary(modelo_PARCELASUB)
modelo = modelo_PARCELASUB
```

```{r}
# Refazer o modelo sem o erro, apenas para facilitar as funções subsequentes
modelo = aov(Na ~ BLOCO + INOCULO * EFLUENTE,
             data = blocos_dados_4)

# Realizar a análise de variância (ANOVA)
anova_result <- anova(modelo)

# Filtrar apenas os fatores significativos ao nível 0.05
fatores_significativos <- anova_result[anova_result$"Pr(>F)" < 0.05, ]

# Exibir as interações significativas
print(fatores_significativos)
```

```{r}
# Vetor com os fatores significativos
nomes_linhas = row.names(fatores_significativos)

# Filtrar apenas as interações
interacoes_significativas <- nomes_linhas[nchar(nomes_linhas) > 8]

# Exibir o resultado
print(interacoes_significativas)
```

```{r}
# Realizar o teste de Tukey para todas as interações significativas
tukey_result <- TukeyHSD(modelo)
```

```{r}
for (i in 1:length(interacoes_significativas)) {
  if (length(interacoes_significativas) == 0){
    break
  }
  interacao = interacoes_significativas[i]
  partes <- strsplit(interacao, split = ":")
  if (nchar(interacao) < 20){
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- 0
  }
  else{
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- partes[[1]][3]
  }
  
  if(fator1 == "INOCULO" && fator2 == "EFLUENTE" && fator3 == 0){
    media_interacao <- aggregate(Na ~ INOCULO + EFLUENTE, 
                             data = blocos_dados_4, FUN = mean)
    print(media_interacao)
  }

}
```

```{r}
for (i in 1:length(interacoes_significativas)) {
  if (length(interacoes_significativas) == 0){
    break
  }
  interacao = interacoes_significativas[i]
  partes <- strsplit(interacao, split = ":")
  if (nchar(interacao) < 20){
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- 0
  }
  else{
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- partes[[1]][3]
  }
  
  inter_tukey = tukey_result[interacao]
  inter_tukey = data.frame(inter_tukey)
  colnames(inter_tukey) = c('diif','lwr','upr','p_adj')
  inter_tukey = subset(inter_tukey, p_adj < 0.05)
  print(inter_tukey)
}
```

### Análise para Cálcio ###

```{r}
# Gráficos com os boxplots para cada combinação de todos os fatores
ggplot(dados_5, aes(x = factor(EFLUENTE), y = Ca)) +
  geom_boxplot() +
  facet_grid(INOCULO ~ CICLO) +
  labs(x = "EFLUENTE", y = "Cálcio") +
  ggtitle("Boxplots por combinação dos fatores")
```

```{r}
# Calcular os limites inferiores de outliers para cada combinação de fatores
limites_outliers <- aggregate(Ca ~ EFLUENTE + INOCULO + CICLO, 
                              data = dados_5, FUN = function(x) {
  q <- quantile(x, c(0.25, 0.75), na.rm = TRUE)
  iqr <- q[2] - q[1]
  limite_inferior <- q[1] - 1.5 * iqr
})

# Armazenar vetor com os limites inferiores
lim_inf = limites_outliers$Ca

# Calcular os limites superiores de outliers para cada combinação de fatores
limites_outliers <- aggregate(Ca ~ EFLUENTE + INOCULO + CICLO, 
                              data = dados_5, FUN = function(x) {
  q <- quantile(x, c(0.25, 0.75), na.rm = TRUE)
  iqr <- q[2] - q[1]
  limite_superior <- q[2] + 1.5 * iqr
})

# Armazenar vetor com os limites superiores
lim_sup = limites_outliers$Ca

# Montar Dataframe com os limites inferior e superior
limites_outliers = limites_outliers[c(1:3)]
limites_outliers$LIM_INF = lim_inf
limites_outliers$LIM_SUP = lim_sup

# Definir o número de replicação de acordo com o valor de CICLO
num_rep <- ifelse(limites_outliers$CICLO == 1, 4, 3)

# Replicar as linhas do dataframe
limites_outliers <- limites_outliers[rep(row.names(limites_outliers), 
                                         num_rep), ]

# Redefinir os índices das linhas
rownames(limites_outliers) <- NULL

# Reordenar os dados do tempo 1 seguindo a combinação de fatores por cada bloco
blocos_dados_5 <- with(dados_5, 
                             dados_5[order(CICLO, INOCULO, EFLUENTE), ])

# Definir como NA (valor ausente) os outliers
blocos_dados_5$Ca[which(blocos_dados_5$Ca < 
                                    limites_outliers$LIM_INF)] = NA
blocos_dados_5$Ca[which(blocos_dados_5$Ca > 
                                    limites_outliers$LIM_SUP)] = NA

# Calcular a média para cada grupo de 4 linhas
media_blocos_5 = aggregate(Ca ~ EFLUENTE + INOCULO + CICLO, 
                                 data = blocos_dados_5, FUN = mean)

# Replicar cada linha por 4 vezes
media_blocos_5 = media_blocos_5[rep(row.names(media_blocos_5), 
                                                each = 4), ]

# Redefinir os índices das linhas
rownames(media_blocos_5) <- NULL

# Preencher os NA's com as médias dos 4 blocos para a 
# combinação de fatores específica
blocos_dados_5$Ca[which(is.na(blocos_dados_5$Ca))] =
  media_blocos_5$Ca[which(is.na(blocos_dados_5$Ca))]

```

```{r}
# Análises Descritivas
str(blocos_dados_5)
summary(blocos_dados_5)

# Número de observações
with(blocos_dados_5, tapply(Ca, list(EFLUENTE, INOCULO), length))
with(blocos_dados_5, tapply(Ca, list(EFLUENTE, INOCULO), sum))
with(blocos_dados_5, tapply(Ca, list(EFLUENTE, INOCULO), mean))
with(blocos_dados_5, tapply(Ca, list(EFLUENTE, INOCULO), var))
with(blocos_dados_5, tapply(Ca, list(EFLUENTE, INOCULO), sd))

# Tamanho das Médias
T.medias <- with(blocos_dados_5,
                 model.tables(aov(Ca ~ BLOCO + EFLUENTE + INOCULO +
                                    EFLUENTE:INOCULO),
                              "means"))
T.medias
```

```{r}
# Media dos blocos para fazer os testes de Normalidade e Homocedasticidade
media_blocos_5 = aggregate(Ca ~ EFLUENTE + INOCULO + CICLO, 
                                 data = blocos_dados_5, FUN = mean)

# Realizar o teste Shapiro-Wilk no conjunto de dados completo
resultado_shapiro <- shapiro.test(media_blocos_5$Ca)$p.value

# Exibir o resultado do teste Shapiro-Wilk
print(resultado_shapiro)

# Interpretação do p-valor
if (resultado_shapiro > 0.05) {
  print("Os dados seguem uma distribuição normal.")
} else {
  print("Os dados não seguem uma distribuição normal.")
}
```

```{r}
# Realizar o teste de Bartlett no conjunto de dados completo
resultado_bartlett <- bartlett.test(media_blocos_5$Ca, 
                                    media_blocos_5$EFLUENTE, 
                                    media_blocos_5$INOCULO,
                                    media_blocos_5$CICLO)$p.value

# Exibir o resultado do teste de Bartlett
print(resultado_bartlett)

# Interpretação do p-valor
if (resultado_bartlett > 0.05) {
  print("A variância é homogênea entre os grupos.")
} else {
  print("A variância não é homogênea entre os grupos.")
}
```


```{r}
# Ajustar o modelo linear para parcelas subdivididas
modelo_PARCELASUB = aov(Ca ~ BLOCO + INOCULO * EFLUENTE + 
                          Error(BLOCO*INOCULO), data = blocos_dados_5)

# Visualizar os resultados do modelo
summary(modelo_PARCELASUB)
modelo = modelo_PARCELASUB
```

```{r}
# Refazer o modelo sem o erro, apenas para facilitar as funções subsequentes
modelo = aov(Ca ~ BLOCO + INOCULO * EFLUENTE,
             data = blocos_dados_5)

# Realizar a análise de variância (ANOVA)
anova_result <- anova(modelo)

# Filtrar apenas os fatores significativos ao nível 0.05
fatores_significativos <- anova_result[anova_result$"Pr(>F)" < 0.05, ]

# Exibir as interações significativas
print(fatores_significativos)
```

```{r}
# Vetor com os fatores significativos
nomes_linhas = row.names(fatores_significativos)

# Filtrar apenas as interações
interacoes_significativas <- nomes_linhas[nchar(nomes_linhas) > 8]

# Exibir o resultado
print(interacoes_significativas)
```

```{r}
# Realizar o teste de Tukey para todas as interações significativas
tukey_result <- TukeyHSD(modelo)
```

```{r}
for (i in 1:length(interacoes_significativas)) {
  if (length(interacoes_significativas) == 0){
    break
  }
  interacao = interacoes_significativas[i]
  partes <- strsplit(interacao, split = ":")
  if (nchar(interacao) < 20){
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- 0
  }
  else{
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- partes[[1]][3]
  }
  
  if(fator1 == "INOCULO" && fator2 == "EFLUENTE" && fator3 == 0){
    media_interacao <- aggregate(Ca ~ INOCULO + EFLUENTE, 
                             data = blocos_dados_5, FUN = mean)
    print(media_interacao)
  }

}
```

```{r}
for (i in 1:length(interacoes_significativas)) {
  if (length(interacoes_significativas) == 0){
    break
  }
  interacao = interacoes_significativas[i]
  partes <- strsplit(interacao, split = ":")
  if (nchar(interacao) < 20){
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- 0
  }
  else{
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- partes[[1]][3]
  }
  
  inter_tukey = tukey_result[interacao]
  inter_tukey = data.frame(inter_tukey)
  colnames(inter_tukey) = c('diif','lwr','upr','p_adj')
  inter_tukey = subset(inter_tukey, p_adj < 0.05)
  print(inter_tukey)
}
```

### Análise para Magnésio ###

```{r}
# Gráficos com os boxplots para cada combinação de todos os fatores
ggplot(dados_6, aes(x = factor(EFLUENTE), y = Mg)) +
  geom_boxplot() +
  facet_grid(INOCULO ~ CICLO) +
  labs(x = "EFLUENTE", y = "Magnésio") +
  ggtitle("Boxplots por combinação dos fatores")
```

```{r}
# Calcular os limites inferiores de outliers para cada combinação de fatores
limites_outliers <- aggregate(Mg ~ EFLUENTE + INOCULO + CICLO, 
                              data = dados_6, FUN = function(x) {
  q <- quantile(x, c(0.25, 0.75), na.rm = TRUE)
  iqr <- q[2] - q[1]
  limite_inferior <- q[1] - 1.5 * iqr
})

# Armazenar vetor com os limites inferiores
lim_inf = limites_outliers$Mg

# Calcular os limites superiores de outliers para cada combinação de fatores
limites_outliers <- aggregate(Mg ~ EFLUENTE + INOCULO + CICLO, 
                              data = dados_6, FUN = function(x) {
  q <- quantile(x, c(0.25, 0.75), na.rm = TRUE)
  iqr <- q[2] - q[1]
  limite_superior <- q[2] + 1.5 * iqr
})

# Armazenar vetor com os limites superiores
lim_sup = limites_outliers$Mg

# Montar Dataframe com os limites inferior e superior
limites_outliers = limites_outliers[c(1:3)]
limites_outliers$LIM_INF = lim_inf
limites_outliers$LIM_SUP = lim_sup

# Definir o número de replicação de acordo com o valor de CICLO
num_rep <- ifelse(limites_outliers$CICLO == 1, 4, 3)

# Replicar as linhas do dataframe
limites_outliers <- limites_outliers[rep(row.names(limites_outliers), 
                                         num_rep), ]

# Redefinir os índices das linhas
rownames(limites_outliers) <- NULL

# Reordenar os dados do tempo 1 seguindo a combinação de fatores por cada bloco
blocos_dados_6 <- with(dados_6, 
                             dados_6[order(CICLO, INOCULO, EFLUENTE), ])

# Definir como NA (valor ausente) os outliers
blocos_dados_6$Mg[which(blocos_dados_6$Mg < 
                                    limites_outliers$LIM_INF)] = NA
blocos_dados_6$Mg[which(blocos_dados_6$Mg > 
                                    limites_outliers$LIM_SUP)] = NA

# Calcular a média para cada grupo de 4 linhas
media_blocos_6 = aggregate(Mg ~ EFLUENTE + INOCULO + CICLO, 
                                 data = blocos_dados_6, FUN = mean)

# Replicar cada linha por 4 vezes
media_blocos_6 = media_blocos_6[rep(row.names(media_blocos_6), 
                                                each = 4), ]

# Redefinir os índices das linhas
rownames(media_blocos_6) <- NULL

# Preencher os NA's com as médias dos 4 blocos para a 
# combinação de fatores específica
blocos_dados_6$Mg[which(is.na(blocos_dados_6$Mg))] =
  media_blocos_6$Mg[which(is.na(blocos_dados_6$Mg))]
```

```{r}
# Análises Descritivas
str(blocos_dados_6)
summary(blocos_dados_6)

# Número de observações
with(blocos_dados_6, tapply(Mg, list(EFLUENTE, INOCULO), length))
with(blocos_dados_6, tapply(Mg, list(EFLUENTE, INOCULO), sum))
with(blocos_dados_6, tapply(Mg, list(EFLUENTE, INOCULO), mean))
with(blocos_dados_6, tapply(Mg, list(EFLUENTE, INOCULO), var))
with(blocos_dados_6, tapply(Mg, list(EFLUENTE, INOCULO), sd))

# Tamanho das Médias
T.medias <- with(blocos_dados_6,
                 model.tables(aov(Mg ~ BLOCO + EFLUENTE + INOCULO +
                                    EFLUENTE:INOCULO),
                              "means"))
T.medias
```

```{r}
# Media dos blocos para fazer os testes de Normalidade e Homocedasticidade
media_blocos_6 = aggregate(Mg ~ EFLUENTE + INOCULO + CICLO, 
                                 data = blocos_dados_6, FUN = mean)

# Realizar o teste Shapiro-Wilk no conjunto de dados completo
resultado_shapiro <- shapiro.test(media_blocos_6$Mg)$p.value

# Exibir o resultado do teste Shapiro-Wilk
print(resultado_shapiro)

# Interpretação do p-valor
if (resultado_shapiro > 0.05) {
  print("Os dados seguem uma distribuição normal.")
} else {
  print("Os dados não seguem uma distribuição normal.")
}
```

```{r}
# Realizar o teste de Bartlett no conjunto de dados completo
resultado_bartlett <- bartlett.test(media_blocos_6$Mg, 
                                    media_blocos_6$EFLUENTE, 
                                    media_blocos_6$INOCULO,
                                    media_blocos_6$CICLO)$p.value

# Exibir o resultado do teste de Bartlett
print(resultado_bartlett)

# Interpretação do p-valor
if (resultado_bartlett > 0.05) {
  print("A variância é homogênea entre os grupos.")
} else {
  print("A variância não é homogênea entre os grupos.")
}
```

```{r}
# Ajustar o modelo linear para parcelas subdivididas
modelo_PARCELASUB = aov(Mg ~ BLOCO + INOCULO * EFLUENTE + 
                          Error(BLOCO*INOCULO), data = blocos_dados_6)

# Visualizar os resultados do modelo
summary(modelo_PARCELASUB)
modelo = modelo_PARCELASUB
```

```{r}
# Refazer o modelo sem o erro, apenas para facilitar as funções subsequentes
modelo = aov(Mg ~ BLOCO + INOCULO * EFLUENTE,
             data = blocos_dados_6)

# Realizar a análise de variância (ANOVA)
anova_result <- anova(modelo)

# Filtrar apenas os fatores significativos ao nível 0.05
fatores_significativos <- anova_result[anova_result$"Pr(>F)" < 0.05, ]

# Exibir as interações significativas
print(fatores_significativos)
```

```{r}
# Vetor com os fatores significativos
nomes_linhas = row.names(fatores_significativos)

# Filtrar apenas as interações
interacoes_significativas <- nomes_linhas[nchar(nomes_linhas) > 8]

# Exibir o resultado
print(interacoes_significativas)
```

```{r}
# Realizar o teste de Tukey para todas as interações significativas
tukey_result <- TukeyHSD(modelo)
```

```{r}
for (i in 1:length(interacoes_significativas)) {
  if (length(interacoes_significativas) == 0){
    break
  }
  interacao = interacoes_significativas[i]
  partes <- strsplit(interacao, split = ":")
  if (nchar(interacao) < 20){
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- 0
  }
  else{
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- partes[[1]][3]
  }
  
  if(fator1 == "INOCULO" && fator2 == "EFLUENTE" && fator3 == 0){
    media_interacao <- aggregate(Mg ~ INOCULO + EFLUENTE, 
                             data = blocos_dados_6, FUN = mean)
    print(media_interacao)
  }

}
```

```{r}
for (i in 1:length(interacoes_significativas)) {
  if (length(interacoes_significativas) == 0){
    break
  }
  interacao = interacoes_significativas[i]
  partes <- strsplit(interacao, split = ":")
  if (nchar(interacao) < 20){
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- 0
  }
  else{
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- partes[[1]][3]
  }
  
  inter_tukey = tukey_result[interacao]
  inter_tukey = data.frame(inter_tukey)
  colnames(inter_tukey) = c('diif','lwr','upr','p_adj')
  inter_tukey = subset(inter_tukey, p_adj < 0.05)
  print(inter_tukey)
}
```

### Análise para Enxofre ###

```{r}
# Gráficos com os boxplots para cada combinação de todos os fatores
ggplot(dados_7, aes(x = factor(EFLUENTE), y = S)) +
  geom_boxplot() +
  facet_grid(INOCULO ~ CICLO) +
  labs(x = "EFLUENTE", y = "Enxofre") +
  ggtitle("Boxplots por combinação dos fatores")
```

```{r}
# Calcular os limites inferiores de outliers para cada combinação de fatores
limites_outliers <- aggregate(S ~ EFLUENTE + INOCULO + CICLO, 
                              data = dados_7, FUN = function(x) {
  q <- quantile(x, c(0.25, 0.75), na.rm = TRUE)
  iqr <- q[2] - q[1]
  limite_inferior <- q[1] - 1.5 * iqr
})

# Armazenar vetor com os limites inferiores
lim_inf = limites_outliers$S

# Calcular os limites superiores de outliers para cada combinação de fatores
limites_outliers <- aggregate(S ~ EFLUENTE + INOCULO + CICLO, 
                              data = dados_7, FUN = function(x) {
  q <- quantile(x, c(0.25, 0.75), na.rm = TRUE)
  iqr <- q[2] - q[1]
  limite_superior <- q[2] + 1.5 * iqr
})

# Armazenar vetor com os limites superiores
lim_sup = limites_outliers$S

# Montar Dataframe com os limites inferior e superior
limites_outliers = limites_outliers[c(1:3)]
limites_outliers$LIM_INF = lim_inf
limites_outliers$LIM_SUP = lim_sup

# Definir o número de replicação de acordo com o valor de CICLO
num_rep <- ifelse(limites_outliers$CICLO == 1, 4, 3)

# Replicar as linhas do dataframe
limites_outliers <- limites_outliers[rep(row.names(limites_outliers), 
                                         num_rep), ]

# Redefinir os índices das linhas
rownames(limites_outliers) <- NULL

# Reordenar os dados do tempo 1 seguindo a combinação de fatores por cada bloco
blocos_dados_7 <- with(dados_7, 
                             dados_7[order(CICLO, INOCULO, EFLUENTE), ])

# Definir como NA (valor ausente) os outliers
blocos_dados_7$S[which(blocos_dados_7$S < 
                                    limites_outliers$LIM_INF)] = NA
blocos_dados_7$S[which(blocos_dados_7$S > 
                                    limites_outliers$LIM_SUP)] = NA

# Calcular a média para cada grupo de 4 linhas
media_blocos_7 = aggregate(S ~ EFLUENTE + INOCULO + CICLO, 
                                 data = blocos_dados_7, FUN = mean)

# Replicar cada linha por 4 vezes
media_blocos_7 = media_blocos_7[rep(row.names(media_blocos_7), 
                                                each = 4), ]

# Redefinir os índices das linhas
rownames(media_blocos_7) <- NULL

# Preencher os NA's com as médias dos 4 blocos para a 
# combinação de fatores específica
blocos_dados_7$S[which(is.na(blocos_dados_7$S))] =
  media_blocos_7$S[which(is.na(blocos_dados_7$S))]
```


```{r}
# Análises Descritivas
str(blocos_dados_7)
summary(blocos_dados_7)

# Número de observações
with(blocos_dados_7, tapply(S, list(EFLUENTE, INOCULO), length))
with(blocos_dados_7, tapply(S, list(EFLUENTE, INOCULO), sum))
with(blocos_dados_7, tapply(S, list(EFLUENTE, INOCULO), mean))
with(blocos_dados_7, tapply(S, list(EFLUENTE, INOCULO), var))
with(blocos_dados_7, tapply(S, list(EFLUENTE, INOCULO), sd))

# Tamanho das Médias
T.medias <- with(blocos_dados_7,
                 model.tables(aov(S ~ BLOCO + EFLUENTE + INOCULO +
                                    EFLUENTE:INOCULO),
                              "means"))
T.medias
```

```{r}
# Media dos blocos para fazer os testes de Normalidade e Homocedasticidade
media_blocos_7 = aggregate(S ~ EFLUENTE + INOCULO + CICLO, 
                                 data = blocos_dados_7, FUN = mean)

# Realizar o teste Shapiro-Wilk no conjunto de dados completo
resultado_shapiro <- shapiro.test(media_blocos_7$S)$p.value

# Exibir o resultado do teste Shapiro-Wilk
print(resultado_shapiro)

# Interpretação do p-valor
if (resultado_shapiro > 0.05) {
  print("Os dados seguem uma distribuição normal.")
} else {
  print("Os dados não seguem uma distribuição normal.")
}
```

```{r}
# Realizar o teste de Bartlett no conjunto de dados completo
resultado_bartlett <- bartlett.test(media_blocos_7$S, 
                                    media_blocos_7$EFLUENTE, 
                                    media_blocos_7$INOCULO,
                                    media_blocos_7$CICLO)$p.value

# Exibir o resultado do teste de Bartlett
print(resultado_bartlett)

# Interpretação do p-valor
if (resultado_bartlett > 0.05) {
  print("A variância é homogênea entre os grupos.")
} else {
  print("A variância não é homogênea entre os grupos.")
}
```

```{r}
# Ajustar o modelo linear para parcelas subdivididas
modelo_PARCELASUB = aov(S ~ BLOCO + INOCULO * EFLUENTE + 
                          Error(BLOCO*INOCULO), data = blocos_dados_7)

# Visualizar os resultados do modelo
summary(modelo_PARCELASUB)
modelo = modelo_PARCELASUB
```

```{r}
# Refazer o modelo sem o erro, apenas para facilitar as funções subsequentes
modelo = aov(S ~ BLOCO + INOCULO * EFLUENTE,
             data = blocos_dados_7)

# Realizar a análise de variância (ANOVA)
anova_result <- anova(modelo)

# Filtrar apenas os fatores significativos ao nível 0.05
fatores_significativos <- anova_result[anova_result$"Pr(>F)" < 0.05, ]

# Exibir as interações significativas
print(fatores_significativos)
```

```{r}
# Vetor com os fatores significativos
nomes_linhas = row.names(fatores_significativos)

# Filtrar apenas as interações
interacoes_significativas <- nomes_linhas[nchar(nomes_linhas) > 8]

# Exibir o resultado
print(interacoes_significativas)
```

```{r}
# Realizar o teste de Tukey para todas as interações significativas
tukey_result <- TukeyHSD(modelo)
```

```{r}
for (i in 1:length(interacoes_significativas)) {
  if (length(interacoes_significativas) == 0){
    break
  }
  interacao = interacoes_significativas[i]
  partes <- strsplit(interacao, split = ":")
  if (nchar(interacao) < 20){
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- 0
  }
  else{
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- partes[[1]][3]
  }
  
  if(fator1 == "INOCULO" && fator2 == "EFLUENTE" && fator3 == 0){
    media_interacao <- aggregate(S ~ INOCULO + EFLUENTE, 
                             data = blocos_dados_7, FUN = mean)
    print(media_interacao)
  }

}
```

```{r}
for (i in 1:length(interacoes_significativas)) {
  if (length(interacoes_significativas) == 0){
    break
  }
  interacao = interacoes_significativas[i]
  partes <- strsplit(interacao, split = ":")
  if (nchar(interacao) < 20){
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- 0
  }
  else{
    fator1 <- partes[[1]][1]
    fator2 <- partes[[1]][2]
    fator3 <- partes[[1]][3]
  }
  
  inter_tukey = tukey_result[interacao]
  inter_tukey = data.frame(inter_tukey)
  colnames(inter_tukey) = c('diif','lwr','upr','p_adj')
  inter_tukey = subset(inter_tukey, p_adj < 0.05)
  print(inter_tukey)
}
```

```{r}
# Juntar dados em um mesmo dataframe
dados_final = cbind(blocos_dados_1, blocos_dados_2["P"], 
                    blocos_dados_3["K"], blocos_dados_4["Na"],
                    blocos_dados_5["Ca"], blocos_dados_6["Mg"],
                    blocos_dados_7["S"])


# Criar planilha com todos os dados atualizados
library("xlsx")
write.xlsx(dados_final, file = "Foliar atualizado - Ciclo 2.xlsx",
      sheetName = "R - Foliar_2", append = FALSE)
```